<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Ernesto Ramirez</title>
    <link>/post/index.xml</link>
    <description>Recent content in Posts on Ernesto Ramirez</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 04 Jun 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How Much Fun is Maximum Fun?</title>
      <link>/post/2016/06/04/how-much-fun-is-maximum-fun/</link>
      <pubDate>Sat, 04 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016/06/04/how-much-fun-is-maximum-fun/</guid>
      <description>

&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m a big consumer of podcasts. Ever since I started living on my own while in graduate school I&amp;rsquo;ve found that having funny and interesting people in my ears helps me get through the day. Even now that I&amp;rsquo;m cohabiting with my wife I haven&amp;rsquo;t left my trusty podcasts behind. They&amp;rsquo;re great for the long commutes back and forth to San Diego, for reducing my stress while stuck in LA traffic, and for making my laugh while I cook, clean, and exercise.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m a fan and donor (support the things you love!) of one podcast network in particular, &lt;a href=&#34;http://www.maximumfun.org&#34;&gt;Maximum Fun&lt;/a&gt;, so much so that I&amp;rsquo;m a semi-regular participant in their Facebook group and subreddit. Recently, someone in the Facebook group asked for some data about the network, in particular the number of shows that have been published, in order to visualize the growth of the network. As someone who&amp;rsquo;s keen to keep my data analysis skills fresh and nimble I took this as an opportunity to dive back into R. Here&amp;rsquo;s what I&amp;rsquo;ve done so far:&lt;/p&gt;

&lt;h2 id=&#34;gathering-data-from-an-rss-feed&#34;&gt;Gathering Data from an RSS Feed&lt;/h2&gt;

&lt;p&gt;Podcasts are unique in that they&amp;rsquo;re basically just a simple feed of audio files. That feed has data embedded into it that we can access and save. I&amp;rsquo;m pretty new to web-scrapping, but I was able to find a really nice example of &lt;a href=&#34;https://gist.github.com/izahn/5785265&#34;&gt;how to scrape an RSS feed in R here&lt;/a&gt;. I adapted that to scrape and save data from each of the podcasts in the Maximum Fun network. Here&amp;rsquo;s an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(RCurl)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: methods
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: bitops
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(XML)

options(stringsAsFactors = FALSE)

## get rss document
xml.url &amp;lt;- &amp;quot;http://adventurezone.libsyn.com/rss&amp;quot;
script &amp;lt;- getURL(xml.url, ssl.verifypeer = FALSE)

## convert document to XML tree in R
doc &amp;lt;- xmlParse(script)
## find the names of the item nodes

## Extract some information from each node in the rss feed
titles &amp;lt;- xpathSApply(doc,&#39;//item/title&#39;,xmlValue)
date &amp;lt;- xpathSApply(doc,&#39;//item/pubDate&#39;,xmlValue)
duration &amp;lt;- xpathSApply(doc,&#39;//item/itunes:duration&#39;,xmlValue)

# create data frame with important variables
Adventurezone &amp;lt;- data.frame(titles, date, duration)

# create unique identifier
Adventurezone$id &amp;lt;- &amp;quot;The Adventure Zone&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I probably could have created a function to run through all the shows, but instead I used that chunk for every show. It was actually useful as a few of the shows had missing episodes or titles and durations that didn&amp;rsquo;t match up.&lt;/p&gt;

&lt;p&gt;Once I had all the data scrapped from the feeds I was able to combine it into one dataset of 4,202 episodes from 25 different shows. The date/duration variables were pretty messy so I noodled around a bit and cleaned them up into something manageable. I&amp;rsquo;ve saved that final data in &lt;a href=&#34;https://dl.dropboxusercontent.com/u/2513399/MaximumFun.rdata&#34;&gt;Rdata&lt;/a&gt; and &lt;a href=&#34;https://dl.dropboxusercontent.com/u/2513399/MaximumFun.csv&#34;&gt;.csv&lt;/a&gt; formats if you want to play with them yourself. I&amp;rsquo;m loading the RData file here:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;load(url(&amp;quot;https://dl.dropboxusercontent.com/u/2513399/MaximumFun.rdata&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;visualizations&#34;&gt;Visualizations&lt;/h2&gt;

&lt;p&gt;Once we have all the data in a good format creating visualizations is actually pretty easy! Let&amp;rsquo;s start with a simple bar chart that plots the number of shows per month:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
# simple bar chart with sum of number of shows per month
mf.stacked.bar &amp;lt;- ggplot(MaximumFun, aes(monthyear)) + geom_bar() +
  labs(title = &amp;quot;Number of Shows on Maximum Fun per Month&amp;quot;, x = &amp;quot;Year - Month&amp;quot;, y = &amp;quot;Number of Shows Published&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
mf.stacked.bar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-3-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s not bad, but what if we wanted to know which shows were on the network over time? We can use the &amp;ldquo;id&amp;rdquo; variable we created in the initial data scrapping process to label each show. This visualization needs a better color palette to better differentiate between each show, but I&amp;rsquo;ll leave it here for now:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
# add in color to represent the shows
# needs a better color palette
mf.stacked.bar2 &amp;lt;- ggplot(MaximumFun, aes(monthyear, fill = id)) + geom_bar() +
  labs(title = &amp;quot;Number of Shows on Maximum Fun per Month&amp;quot;, x = &amp;quot;Year - Month&amp;quot;, y = &amp;quot;Number of Shows Published&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6), legend.position=&amp;quot;bottom&amp;quot;)
mf.stacked.bar2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-4-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What can we find out about each show? Let&amp;rsquo;s start with visualizing the total number of hours each podcast has published:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
mf.stacked.bar4 &amp;lt;- ggplot(MaximumFun, aes(id, (showlength/60))) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  labs(title = &amp;quot;Total Duration of Each Show on Maximum Fun&amp;quot;, x = &amp;quot;Show&amp;quot;, y = &amp;quot;Total Number of Hours&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
mf.stacked.bar4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-5-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;How about the number of episodes per show?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# simple bar chart for total number of episodes per show
mf.stacked.bar5 &amp;lt;- ggplot(MaximumFun, aes(id)) + geom_bar() +
  labs(title = &amp;quot;Number of Episode of each Show on Maximum Fun&amp;quot;, x = &amp;quot;Show&amp;quot;, y = &amp;quot;Total Number of Episodes&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
mf.stacked.bar5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-6-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I also got around to reformatting the data so that we could look at the number of shows and amount of content produced by Maximum Fun over time. To do that we first have to create a new dataset that aggregates some of the information:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(plyr)
# number of shows on the network over time
MaxFunShows &amp;lt;- ddply(MaximumFun, c(&amp;quot;monthyear&amp;quot;), summarise,
                           &#39;NumberofShows&#39; = length(unique(id)),
                           &#39;DurationofShows&#39; = sum(showlength, na.rm=TRUE)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we can make plots just like the ones we have above!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mf.stacked.bar5 &amp;lt;- ggplot(MaxFunShows, aes(monthyear, NumberofShows)) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  labs(title = &amp;quot;Number of Shows on Maximum Fun over time&amp;quot;, x = &amp;quot;Date&amp;quot;, y = &amp;quot;Number of Shows on the Network&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
mf.stacked.bar5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-8-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-8&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What about the amount of content over time?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mf.stacked.bar5 &amp;lt;- ggplot(MaxFunShows, aes(monthyear, (DurationofShows/60))) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  labs(title = &amp;quot;Amount of Content Produced (in hours) by Maximum Fun over time&amp;quot;, x = &amp;quot;Date&amp;quot;, y = &amp;quot;Hours&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
mf.stacked.bar5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-9-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-9&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, this doesn&amp;rsquo;t include some of the great shows that have moved on to be either independtly operated or part of another network, but it&amp;rsquo;s still a pretty good approximation of the growth over time.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll probably keep noodling around with this data. Probably a lot more I can do with visualizing particular shows and the network as a whole. If you have ideas &lt;a href=&#34;http://twitter.com/eramirez&#34;&gt;get in touch&lt;/a&gt;!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I&#39;m the Doctor Now</title>
      <link>/post/2016/05/27/im-the-doctor-now/</link>
      <pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016/05/27/im-the-doctor-now/</guid>
      <description>&lt;p&gt;Well, it&amp;rsquo;s finally done. Eight years after I started this crazy graduate school journey I&amp;rsquo;ve successfully defended my dissertation. It wasn&amp;rsquo;t easy, it wasn&amp;rsquo;t perfect, but it&amp;rsquo;s done and I couldn&amp;rsquo;t be happier to have accomplished this milestone.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/images/dissertation.jpeg&#34; alt=&#34;dissertation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Some folks have asked to see the slides, so I thought I&amp;rsquo;d share them here. Hopefully they make sense, but don&amp;rsquo;t worry if they don&amp;rsquo;t. I&amp;rsquo;ll be posting more about this work in the future.&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;350de98f9213495c886f75311af89fd3&#34; data-ratio=&#34;1.33333333333333&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing Time Series Data</title>
      <link>/post/2016/01/25/visualizing-time-series-data/</link>
      <pubDate>Mon, 25 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016/01/25/visualizing-time-series-data/</guid>
      <description>

&lt;p&gt;When working with human behavior you&amp;rsquo;ll almost always have to deal with data that is formatted as a time series. Briefly, time series data corresponds with repeated measures of a variable (or multiple variables) at consistent intervals over a period.&lt;/p&gt;

&lt;p&gt;At the Center for Wireless and Population Health Systems, we&amp;rsquo;re consistently dealing with physical activity data collected from accelerometers worn by study participants. These measurement devices sample human locomotion at various rates over periods lasting days, weeks, or even longer. There are a variety of methods to process and analyze accelerometer data, but we know any good statistician will use a variety of visualization techniques so become familiar with the data and understand it better. This document is meant to be an introduction to different methods for visualizing time series data. By no means does it cover &lt;em&gt;every&lt;/em&gt; method, but it should get you started and give you some ideas for additional techniques.&lt;/p&gt;

&lt;h2 id=&#34;the-data&#34;&gt;The Data&lt;/h2&gt;

&lt;p&gt;The data used in these examples was collected as part of my doctoral dissertation research. The physical activity data was gathered from participants who used a Fitbit activity tracker to measure their physical activity. Access to historical data was granted by participants and downloaded using &lt;a href=&#34;http://fitabase.com&#34;&gt;Fitabase&lt;/a&gt;. A variety of data was made available, but for this example we&amp;rsquo;ll be focusing on steps.&lt;/p&gt;

&lt;p&gt;As my dissertation analysis is ongoing, I&amp;rsquo;m using my own Fitbit data here for this example.&lt;/p&gt;

&lt;h2 id=&#34;step-data&#34;&gt;Step Data&lt;/h2&gt;

&lt;p&gt;I downloaded my step data over a two-year period from Jan. 1, 2012 to Jan. 1, 2014. Two data files will be used in this analysis (click to download the data sets):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://dl.dropboxusercontent.com/u/2513399/ER_FitbitDailySteps_2012.csv&#34;&gt;Daily Steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dl.dropboxusercontent.com/u/2513399/ER_FitbitMinuteSteps_2012.csv&#34;&gt;Minute-Level Steps&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The &lt;strong&gt;Daily Steps&lt;/strong&gt; file contains 366 observations of the total amount of steps recorded for each day in 2012 (2012 was a leap year). The &lt;strong&gt;Minute-Level Steps&lt;/strong&gt; file contains 527,040 observations (1,440 minutes per hour, 24 hours, 366 days) of the total steps recorded per minute for 2012.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s load &amp;lsquo;em up.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;DailySteps &amp;lt;- read.csv(&amp;quot;https://dl.dropboxusercontent.com/u/2513399/ER_FitbitDailySteps_2012.csv&amp;quot;)
MinuteSteps &amp;lt;- read.csv(&amp;quot;https://dl.dropboxusercontent.com/u/2513399/ER_FitbitMinuteSteps_2012.csv&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cleaning-the-data&#34;&gt;Cleaning the data&lt;/h2&gt;

&lt;p&gt;So the data is loaded and a quick glance indicates that the date and date/time vectors were imported as &lt;em&gt;factors&lt;/em&gt;. That&amp;rsquo;s all well and good for most things, but we&amp;rsquo;re going to want dates as dates and times as times for visualization purposes. Let&amp;rsquo;s get those corrected. I like using the &lt;a href=&#34;https://cran.r-project.org/web/packages/lubridate/index.html&#34;&gt;lubridate package&lt;/a&gt; as it handles dates and times very easily. The &lt;em&gt;ActivityDay&lt;/em&gt; vector is in mm/dd/yyyy format so we can use the &lt;em&gt;mdy&lt;/em&gt; function from lubridate to change it into a POSIXct variable.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(lubridate)
DailySteps$Date &amp;lt;- mdy(DailySteps$ActivityDay)
DailySteps$Date &amp;lt;- as.Date(DailySteps$Date)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The minute-level data is a bit trickier. The &lt;em&gt;ActivityMinute&lt;/em&gt; vector is formatted for date/time in mm/dd/yyyy hh:mm:ss AM/PM. This isn&amp;rsquo;t super useful for instance, when we want to plot the minute-by-minute steps for a full day of data. So let&amp;rsquo;s do some reformatting to clean it up.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;MinuteSteps$ActivityMinute &amp;lt;- mdy_hms(as.character(MinuteSteps$ActivityMinute))
MinuteSteps$Date &amp;lt;- as.Date(MinuteSteps$ActivityMinute, format = &amp;quot;%Y-%m-%d  %H:%M:%S&amp;quot;)
MinuteSteps$Time &amp;lt;- format(as.POSIXct(strptime(MinuteSteps$ActivityMinute, &amp;quot;%Y-%m-%d  %H:%M:%S&amp;quot;,tz=&amp;quot;&amp;quot;)) ,format = &amp;quot;%H:%M&amp;quot;)
MinuteSteps$Time &amp;lt;- as.POSIXct(MinuteSteps$Time, format = &amp;quot;%H:%M&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Why four steps to create two variables? Well, we want to make the date, a date variable, and we also want to strip the time to it&amp;rsquo;s own variable. strptime can do that, but it returns a character vector, which ggplot won&amp;rsquo;t like when use it as a scale. We have to convert that time character vector back into POSIXct and by doing so we assign it an arbitrary date. If you don&amp;rsquo;t assign it in the function then it will automatically assign today&amp;rsquo;s date.&lt;/p&gt;

&lt;p&gt;#Fist Level Visualization - Bars &amp;amp; Lines&lt;/p&gt;

&lt;h2 id=&#34;bar-plots&#34;&gt;Bar Plots&lt;/h2&gt;

&lt;p&gt;I find bar plots a bit easier to read when dealing with aggregated data such as daily step counts. This might be because I envision the volume of the bar to contain the total amount of steps for that day. So let&amp;rsquo;s make a quick bar plot of the Daily Steps.&lt;/p&gt;

&lt;p&gt;Before we begin we&amp;rsquo;ll need to load two packages: &lt;strong&gt;ggplot2&lt;/strong&gt; and &lt;strong&gt;scales&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
DailyStepsPlot &amp;lt;- ggplot(DailySteps, aes(x=Date, y=StepTotal)) #This will base plot which we&#39;ll manipulate.

DailyStepsPlot + geom_bar(stat=&amp;quot;identity&amp;quot;) + scale_x_date(breaks=date_breaks(&amp;quot;1 month&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-4-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;##Line Plots
What about a line plot (with added points)?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-5-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-5&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;multiple-line-plots&#34;&gt;Multiple Line Plots&lt;/h2&gt;

&lt;p&gt;Line plots aren&amp;rsquo;t that great when you have a continuous data set that spans over 500,000 observations. For a data set that large we&amp;rsquo;re typically trying to look into patterns. A good way to do that is to plot the data one level up, such as per day in this case.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll plot each day on the same canvas with each line set to a transparency of alpha = .05. I also cut down the line size so that patterns might be seen in the resulting banding.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(MinuteSteps, aes(x=Time, y=Steps, group=Date)) +
  geom_path(size=.5, alpha = 0.05, colour=&amp;quot;blue&amp;quot;) +
  scale_x_datetime(breaks=date_breaks(&amp;quot;2 hour&amp;quot;), labels=date_format(&amp;quot;%H:%M&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-6-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can see some clear banding at 120 steps/min or so and another a bit lower around 75 steps/min. It also appears that there a few days with periods of high activity (&amp;gt;150 steps/min) just past 6PM (18:00). But, could it be clearer?&lt;/p&gt;

&lt;h2 id=&#34;scatterplot&#34;&gt;Scatterplot&lt;/h2&gt;

&lt;p&gt;When using the line graph, multiple lines can obscure the patterns we&amp;rsquo;re trying to tease out by introducing a bit of visual noise. Let&amp;rsquo;s reduce the noise by taking away the lines and using just points in a scatterplot.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(MinuteSteps, aes(x=Time, y=Steps, group=Date)) +
  geom_point(size=.5, alpha = 0.1, colour=&amp;quot;blue&amp;quot;) +
  scale_x_datetime(breaks=date_breaks(&amp;quot;2 hour&amp;quot;), labels=date_format(&amp;quot;%H:%M&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-7-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-7&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;grouping-data-multiple-lines-facets-wrapping&#34;&gt;Grouping Data (Multiple Lines &amp;amp; Facets Wrapping)&lt;/h2&gt;

&lt;p&gt;So we&amp;rsquo;ve plotted every day, and we&amp;rsquo;ve plotted every minute in our data. We&amp;rsquo;ve teased out a few simple patterns, but what about other distinctions in the data?&lt;/p&gt;

&lt;p&gt;One of the methods common in physical activity data analysis is to explore differences across different days of the week. Are individuals more active on certain days of the week? How about the difference between weekdays and weekend days?&lt;/p&gt;

&lt;p&gt;To be able to create visualizations that help us understand these potential differences we&amp;rsquo;ll have to do a bit of work on the data.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s create a &lt;em&gt;Day&lt;/em&gt; variable for our Daily data set. Again, we&amp;rsquo;re turning to the &lt;strong&gt;lubridate&lt;/strong&gt; package. Lubridate has function called &lt;strong&gt;&lt;em&gt;wday&lt;/em&gt;&lt;/strong&gt; which will return the day of the week.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;DailySteps$Day &amp;lt;- wday(DailySteps$Date, label = TRUE) # we use labels=true here to return day labels instead of numeric values.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s see if we can plot differences between days:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(DailySteps, aes(x=Date, y=StepTotal, group=Day, colour=Day)) + geom_path() + geom_point() + scale_x_date(breaks=date_breaks(&amp;quot;1 month&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-9-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-9&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Well, that&amp;rsquo;s a mess. What if we graph each day individually? We can do this by calling creating multiple facets of the same plot.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(DailySteps, aes(x=Date, y=StepTotal, colour=Day)) +
  geom_path() +
  geom_point() +
  scale_x_date(breaks=date_breaks(&amp;quot;1 month&amp;quot;)) +
  facet_grid(Day ~.) +
  theme(legend.position=&amp;quot;none&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-10-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-10&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s a bit better, but I personally think the week starts on Monday, not Sunday. Let&amp;rsquo;s fix that in our data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;DailySteps$Day2 &amp;lt;- factor(DailySteps$Day, levels = c(&amp;quot;Mon&amp;quot;, &amp;quot;Tues&amp;quot;, &amp;quot;Wed&amp;quot;, &amp;quot;Thurs&amp;quot;, &amp;quot;Fri&amp;quot;, &amp;quot;Sat&amp;quot;, &amp;quot;Sun&amp;quot;))

ggplot(DailySteps, aes(x=Date, y=StepTotal, colour=Day2)) +
  geom_path() +
  geom_point() +
  scale_x_date(breaks=date_breaks(&amp;quot;1 month&amp;quot;)) +
  facet_grid(Day2 ~.) +
  theme(legend.position=&amp;quot;none&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-11-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-11&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Okay, that was fun. But let&amp;rsquo;s get to the minute data. We&amp;rsquo;re basically going to do the same type of processing on the minute level data to get day of the week and then we&amp;rsquo;ll create a few different plots.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;MinuteSteps$Day &amp;lt;- wday(MinuteSteps$Date, label = TRUE)
MinuteSteps$Day2 &amp;lt;- factor(DailySteps$Day, levels = c(&amp;quot;Mon&amp;quot;, &amp;quot;Tues&amp;quot;, &amp;quot;Wed&amp;quot;, &amp;quot;Thurs&amp;quot;, &amp;quot;Fri&amp;quot;, &amp;quot;Sat&amp;quot;, &amp;quot;Sun&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you might be able to guess, plotting all the minute-level data points, even when coloured by group, is a complete mess. We&amp;rsquo;ll start with a facetted plot.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(MinuteSteps, aes(x=Time, y=Steps, colour=Day2)) +
  geom_point(size=.5, alpha = 0.1) +
  scale_x_datetime(breaks=date_breaks(&amp;quot;2 hour&amp;quot;), labels=date_format(&amp;quot;%H:%M&amp;quot;)) +
  facet_grid(Day2 ~.) +
  theme(legend.position=&amp;quot;none&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-13-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-13&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Well, that&amp;rsquo;s nice to look at, but still hard to understand any type of trends or patterns. Since we have so much data, we can probably better understand what&amp;rsquo;s going on by collapsing it. For instance, we might want to know what an &amp;ldquo;average Monday&amp;rdquo; might look like. That&amp;rsquo;s easy to do!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;MinuteSteps.AvgDays &amp;lt;- aggregate(Steps ~ Time + Day2, MinuteSteps, mean)

ggplot(MinuteSteps.AvgDays, aes(x=Time, y=Steps, colour=Day2)) +
  geom_path() +
  scale_x_datetime(breaks=date_breaks(&amp;quot;2 hour&amp;quot;), labels=date_format(&amp;quot;%H:%M&amp;quot;)) +
  facet_grid(Day2 ~.) +
  theme(legend.position=&amp;quot;none&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-14-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-14&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ode to the Outshot</title>
      <link>/post/2014/03/19/ode-to-the-outshot/</link>
      <pubDate>Wed, 19 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014/03/19/ode-to-the-outshot/</guid>
      <description>&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; lang=&#34;en&#34;&gt;&lt;p&gt;I think the &lt;a href=&#34;https://twitter.com/Bullseye&#34;&gt;@Bullseye&lt;/a&gt; out shots are my new favorite piece of radio.&lt;/p&gt;&amp;mdash; Ernesto Ramirez (@eramirez) &lt;a href=&#34;https://twitter.com/eramirez/statuses/408084903238987776&#34;&gt;December 4, 2013&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;I&amp;rsquo;ve been listening to podcasts for a while. Like most people I started with the juggernaut, This American Life, but quickly opened up my catalogue to other shows and ideas. I&amp;rsquo;m sure if you  were to plot my podcast listening statistics you&amp;rsquo;d see a sharp uptick in hours listened when I started my second round of graduate school almost six years ago in San Diego.&lt;/p&gt;

&lt;p&gt;I moved to San Diego with the belief that my girlfriend (now wife) wouldn&amp;rsquo;t be far behind. I&amp;rsquo;d find a place to settle, get started with the hard business of academic scholarship, and then she&amp;rsquo;d come join me. Six months was our guess. Funny thing about guesses, they&amp;rsquo;re not very reliable.&lt;/p&gt;

&lt;p&gt;Fast forward four months and I was spending Thanksgiving day with my girlfriend eating Boston Market takeout while we took a break form unpacking her belongings at her new apartment in Bristol, CT. She&amp;rsquo;d landed an entry into her dream job. A job that placed her over 2,800 miles away from where I was pursuing my dreams. Not fun, but we preserved.&lt;/p&gt;

&lt;p&gt;All of this is to say that I was alone a lot of the time for the  four years before we synced back up in the same time zone, found our first apartment together, and got married. Sure I had friends, and work, and classes, but there was also the solo meals I made in a old studio apartment or the long walks I took in the barrio (I moved around a lot). During those moments of solitude my companion was always my iPhone and my podcasts.&lt;/p&gt;

&lt;p&gt;Like I said, I&amp;rsquo;ve listened to a bunch. Other&amp;rsquo;s have listened to more, some less. I&amp;rsquo;m probably right in the middle. I stick to comedy and culture mostly. &lt;a href=&#34;http://www.nerdist.com/podcast/nerdist/&#34;&gt;Chris Hardwick&lt;/a&gt; and his knuckled head friends, Matt and Jonah, kept me company on a lot of walks, runs, and bus commutes. &lt;a href=&#34;http://www.radiolab.org/&#34;&gt;Jad and Robert&lt;/a&gt; were a go to for long plane rides. &lt;a href=&#34;http://www.wtfpod.com/&#34;&gt;Marc&lt;/a&gt; came and went depending on my mood. &lt;a href=&#34;http://douglovesmovies.com/&#34;&gt;Doug&lt;/a&gt; was (and is) an entertaining diversion. And of course I can&amp;rsquo;t forget the two pillars &lt;a href=&#34;http://99percentinvisible.org/&#34;&gt;Roman&lt;/a&gt; and &lt;a href=&#34;http://www.thisamericanlife.org/&#34;&gt;Ira&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When I was listening to these voices the same name was mentioned  time and time again - Jesse Thorn. I also kept hearing something about The Sound of Young America off and on, but never really gave it much thought. Then I started listening to John Hodgman dispense Internet Justice on the &lt;a href=&#34;http://maximumfun.org/shows/judge-john-hodgman&#34;&gt;Judge John Hodgman podcast&lt;/a&gt;. Why? I don&amp;rsquo;t really remember. Probably a recommendation online. Maybe Roman? Who knows. It doesn&amp;rsquo;t matter. John was great (still is) and his sidekick, was&amp;hellip; you guessed it, Mr. Jesse Thorn.&lt;/p&gt;

&lt;p&gt;It took a while, probably about six months of listening to Jesse make funny side comments and endearing commentary for me to finally take the time to check out what this whole MaximumFun thing was all about. I dipped my toes in the water with &lt;a href=&#34;http://maximumfun.org/shows/jordan-jesse-go&#34;&gt;Jordan, Jesse, Go!&lt;/a&gt;. It was  great. Funny, smart, irreverent, but sincere and full of truth. I loved it right away. I started listening to the back catalogue. For some reason I went about it the wrong way and just kept going back one episode at a time instead of starting from the beginning. It was a stupid way to do it, but it didn&amp;rsquo;t matter, each joke was still funny. Each story about getting married, having children, moving, getting jobs - basically becoming an adult - was real and moving and often hilarious. Somewhere along the way in my JJGO historical listening project I decided to branch out again and listen to what used to be the Sound of Young America and is now &lt;a href=&#34;http://www.maximumfun.org/shows/bullseye&#34;&gt;Bullseye&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Bullseye was scary and odd to me. It wasn&amp;rsquo;t what I was used to. It was serious. It was interview-based with different segments, but it didn&amp;rsquo;t have an overarching story like a This American Life episode. Plus, I&amp;rsquo;ll be honest, some of the guests just weren&amp;rsquo;t all that interesting to me. But I gave it a try. And I&amp;rsquo;m better for it.&lt;/p&gt;

&lt;p&gt;Jesse likes to say, &amp;ldquo;Bullseye is at it&amp;rsquo;s core, a recommendation show.&amp;rdquo; It&amp;rsquo;s Jesse recommending bits of culture new and old, through his smart, funny, and engaging interviews with the people that make it. It&amp;rsquo;s people like Mark Fraunfelder from BoingBoing or the AV Club telling you about the music, books, and games that you simply must try because &lt;em&gt;they love them&lt;/em&gt;. It&amp;rsquo;s also people talking about the music that&amp;rsquo;s changed their lives.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Stop right here and listen to recent Academy Award winner &lt;a href=&#34;https://soundcloud.com/bullseye-with-jesse-thorn/bobby-lopez-stcml&#34;&gt;Bobby Lopez talk about&lt;/a&gt; &amp;ldquo;Pure Imagination&amp;rdquo; from Charlie and the Chocolate Factory. Really, stop. &lt;a href=&#34;https://soundcloud.com/bullseye-with-jesse-thorn/bobby-lopez-stcml&#34;&gt;Listen&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But the best part of Bullseye, and my current favorite piece of radio, is the Outshot. Each week Bullseye wraps up with a personal recommendation from Jesse  Thorn. These aren&amp;rsquo;t just reviews of the latest albums or movies. It&amp;rsquo;s something deeper and more intense than almost anything you&amp;rsquo;ll hear out there today. Jesse opens himself up the audience to talk about something he really enjoys. It&amp;rsquo;s sincere and heartfelt, &lt;a href=&#34;http://www.nytimes.com/2008/09/07/fashion/weddings/07VOWS.html?_r=1&amp;amp;scp=1&amp;amp;sq=jesse%20thorn&amp;amp;st=cse&#34;&gt;because that&amp;rsquo;s just who he is&lt;/a&gt;. In his wedding announcement in the New York Time nearly six years ago his wife mentions his inability to be insincere, &amp;ldquo;He is not capable of it,&amp;rdquo; she says. &amp;ldquo;He’s so honest and straightforward about what he likes and doesn’t like, and what he’s thinking. And that’s something I admire.” I admire it too. Not just because he&amp;rsquo;s genuine, but also because he&amp;rsquo;s unafraid to share the things he finds endearing and delightful even though others may scoff. He&amp;rsquo;ll to tell you why &lt;a href=&#34;https://soundcloud.com/bullseye-with-jesse-thorn/outshot-babe&#34;&gt;Babe: Pig in the City&lt;/a&gt; is really a heroes tale or why &lt;a href=&#34;https://soundcloud.com/bullseye-with-jesse-thorn/the-outshot-the-muppet-movie&#34;&gt;the Muppet Movie&lt;/a&gt; is about friends and artists dreaming about how to make the world a better place.&lt;/p&gt;

&lt;p&gt;I love the Outshot because Jesse loves these pieces of culture enough to share them with us. And with each segment and his signature sign off, Jesse does what most of use spend our entire lives trying to do, he draws his bow, let his arrow fly and hit the bullseye, again and again. Thanks Jesse.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Epilogue&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So I actually recored my own &amp;ldquo;Ode to the Outshot&amp;rdquo; and you can go &lt;a href=&#34;https://soundcloud.com/erramirez/ode-to-the-outshot&#34;&gt;listen to it here&lt;/a&gt;. It&amp;rsquo;s also embedded below.&lt;/p&gt;

&lt;iframe width=&#34;100%&#34; height=&#34;166&#34; scrolling=&#34;no&#34; frameborder=&#34;no&#34; src=&#34;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/140653808&amp;amp;color=ff5500&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_artwork=true&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;This week is also MaxFunDrive. The yearly pledge drive for the MaximumFun network and the shows they help bring to the world. This year I&amp;rsquo;ve pitched in and become a donor. Each week I listen to about 4-5 hours of MaxFun programming and I&amp;rsquo;m more than happy to chip in what amounts to $1 per episode. That&amp;rsquo;s cheap considering how much entertainment I&amp;rsquo;m getting. If you&amp;rsquo;re a new or old listener you should consider chipping in too. All the &lt;a href=&#34;https://twitter.com/romanmars/status/446427703907213312&#34;&gt;cool kids&lt;/a&gt; are doing it.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;As always, comments are welcome. This post is available &lt;a href=&#34;https://github.com/erramirez/erramirez.github.io/blob/master/_posts/2014-03-19-Ode-to-the-Outshot.md&#34;&gt;on Github&lt;/a&gt; if that’s your style, and &lt;a href=&#34;https://medium.com/ernesto-ramirez/38132ec3ac12&#34;&gt;Medium&lt;/a&gt; if you like that platform. Free free to connect with me on &lt;a href=&#34;https://medium.com/ernesto-ramirez/83680d1a8c1a&#34;&gt;twitter&lt;/a&gt; or &lt;a href=&#34;mailto:er.ramirez@gmail.com&#34;&gt;email&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>Hardware is Hard</title>
      <link>/post/2014/03/18/hardware-is-hard/</link>
      <pubDate>Tue, 18 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014/03/18/hardware-is-hard/</guid>
      <description>&lt;p&gt;&lt;em&gt;I&amp;rsquo;ve been thinking a lot lately about stuff I&amp;rsquo;ve written, but is lost in other ecosystems. I got a Quora notification this evening and it reminded me of something I wrote on that site over two years ago in response to the question, &amp;ldquo;How hard is it for a startup to design hardware like Jawbone UP, Nike+ Fuelband, Fitbit, etc.?&amp;rdquo; I really like my answer, but I&amp;rsquo;m biased (and &amp;ldquo;me&amp;rdquo; is a small sample size). I&amp;rsquo;ve reproduced it here with a few edits and added updates via footnotes. Let me know what you think.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;There is a lot of room to improve upon the design, UI/UX, and hardware of physical activity and tracking devices. For instance, I noticed you didn&amp;rsquo;t mention &lt;a href=&#34;mybasis.com&#34;&gt;Basis&lt;/a&gt;. They are bringing a great new device to market this year that will integrate optically sensed HR, galvanic skin response, and accelerometery in a nicely designed watch.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;When you talk about designing hardware you have to think not just about what is possible now, but also what will be possible over the next five to ten years and begin designing products that take advantage of new &lt;a href=&#34;http://en.wikipedia.org/wiki/Microelectromechanical_systems&#34;&gt;MEMs&lt;/a&gt; technology. For instance, there is a lot of great R&amp;amp;D coming out of MIT that is supporting the creation of &lt;a href=&#34;http://web.mit.edu/newsoffice/2010/accelerometer-0416.html&#34;&gt;even smaller sensors&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another design element to think of is functionality. Not in the sense of does the device work, but rather, how it works around your normal everyday life. My fiancé was considering all three you mention (FitBit, Nike+ Fuelband, UP) and decided to go with the FitBit because she didn&amp;rsquo;t want to be tied to wearing something on her wrist every day that isn&amp;rsquo;t a watch (she&amp;rsquo;s old school).&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; With the new class of open-source wearable microprocessors (&lt;a href=&#34;http://arduino.cc/en/Main/arduinoBoardLilyPad&#34;&gt;LillyPad&lt;/a&gt;, &lt;a href=&#34;http://www.adafruit.com/category/92&#34;&gt;Flora&lt;/a&gt;, etc.) I don&amp;rsquo;t see why in the next few years we can&amp;rsquo;t have our trackers embedded in our clothing.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;This is getting long, but I&amp;rsquo;ll bring up another hardware design that I see really separating the industry - wireless connectivity. I don&amp;rsquo;t mean bluetooth, I mean true send the data to cloud, kind of connectivity. Qualcomm is pioneering this initiative with their new &lt;a href=&#34;http://www.qualcommlife.com/&#34;&gt;Qualcomm Life&lt;/a&gt; venture  and their proprietary machine-to-machine systems. There will be a day soon, if not this year then next, where your FitBit or Nike+ Fuelband or whatever YOU make has a similar chipset to what you find in the Kindle 3G. This is a huge design challenge as battery usage will be altered dramatically, but again nothing that is insurmountable.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Lastly, I think (and I&amp;rsquo;m a bit biased as I&amp;rsquo;m a behavioral scientist)&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;, is that the technology community tends to overly focus on the hardware rather than the user experience design. Yes, it has to work well as Jawbone showed us. Yes, it has look good - Jawbone showed us that too. But, it also has to be tied to an engaging and worthwhile experience. The importance of good design cannot be overstated. Look at what Aza Raskin is doing over at &lt;a href=&#34;http://massivehealth.com/&#34;&gt;Massive Health&lt;/a&gt; and their Eatery app.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:6&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:6&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; Design will win every time. If you&amp;rsquo;re really thinking about building hardware make sure you find an Aza clone (good luck with that) and spend as much if not more time creating, testing, and iterating on the user experience. People will use something because it&amp;rsquo;s cool and different, but the world will use the thing that works, the thing that makes them forget they&amp;rsquo;re interacting with 1&amp;rsquo;s and 0&amp;rsquo;s (you only need to look at the iPhone for confirmation about the importance of experience design).&lt;/p&gt;

&lt;p&gt;Oh, and I guess to really answer your question. It is very, very, very hard to make physical products that work. That doesn&amp;rsquo;t mean it isn&amp;rsquo;t worth it. Fitbit is a great example. They went through many trials after their huge showing at Techcrunch50 in 2008. They missed launch dates, they had some product failures, but they persevered. &lt;a href=&#34;http://allthingsd.com/20120124/amid-increasing-competition-fitbit-scores-12-million-in-funding/&#34;&gt;Now look&lt;/a&gt; at them.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:7&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:7&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;I guess in the end you might be asking the wrong question. Of course it is hard, building cars is hard, doing astrophysics is hard, playing the cello is hard. But here we are with hundreds of cars to choose from, new PhDs staring at the stars every night, and parents enrolling their children in music lessons. Hard will never go away, but being better is always within reach.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;As always, comments are welcome. This post is available &lt;a href=&#34;https://github.com/erramirez/erramirez.github.io/blob/master/_posts/2014-03-19-Hardware-Is-Hard.md&#34;&gt;on Github&lt;/a&gt; if that’s your style, and &lt;a href=&#34;https://medium.com/ernesto-ramirez/38132ec3ac12&#34;&gt;Medium&lt;/a&gt; if you like that platform. Free free to connect with me on &lt;a href=&#34;https://twitter.com/eramirez&#34;&gt;twitter&lt;/a&gt; or &lt;a href=&#34;mailto:er.ramirez@gmail.com&#34;&gt;email&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;The Basis B1 watch/band has since been released. I was lucky enough to get one and have enjoyed wearing it, especially after the new update. I&amp;rsquo;m still waiting on an API&amp;hellip;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;She originally bought a Fitbit One, but lost it pretty quickly. Her sister then bought her a Fitbit Zip that she&amp;rsquo;s been wearing it every day for over a year. She loves it.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;This was an easy prediction to make. We&amp;rsquo;ve already seen some great entries in the wearable sensing clothing from &lt;a href=&#34;http://www.hexoskin.com/en&#34;&gt;Hexoskin&lt;/a&gt;, &lt;a href=&#34;http://www.omsignal.com/&#34;&gt;OMsignal&lt;/a&gt;, and others.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;Maybe I&amp;rsquo;m wrong about this given the current ecosystem of Bluetooth Low Energy devices, but this still kind of irks me. I originally wrote this when I was a heavy Garmin Forerunner user. I went on runs without my phone, which I don&amp;rsquo;t do now, and wanted my GPS watch to automagically upload that data. I still want that, but I&amp;rsquo;m in a shrinking minority and I&amp;rsquo;m probably wrong.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;I was still full on in my PhD program and this is the most  pretentious phrase in this piece. I&amp;rsquo;m leaving it in to remind me that I am not  a behavioral scientist. I am merely an observer.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;No surprise that Jawbone acquired Massive Health and has made some amazing strides in their mobile app design.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:6&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;Seriously look at them. They have a huge market share in the activity tracking sector: &lt;a href=&#34;http://mobihealthnews.com/28825/fitbit-jawbone-nike-had-97-percent-of-fitness-tracker-retail-sales-in-2013/&#34;&gt;67%&lt;/a&gt;. Even with the Force recalls they&amp;rsquo;re the dominant player. Do you hear people saying they are building the Fuelband for cars? I don&amp;rsquo;t.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:7&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Data Dilemma</title>
      <link>/post/2014/03/11/the-data-dilemma/</link>
      <pubDate>Tue, 11 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014/03/11/the-data-dilemma/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;It’s easier than every to measure anything we want, and it’s easier than ever to analyze that data, which means &lt;em&gt;no field of human endeavor is safe from the effects of big data&lt;/em&gt;.      -Derrick Harris, &lt;a href=&#34;http://gigaom.com/2014/03/10/an-mlb-team-is-apparently-doing-in-game-graph-analysis/&#34;&gt;GigOM&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If you&amp;rsquo;re like me you think this is absolutely the best time to be alive. Our current state of technological progress appears to be at an all time high. We&amp;rsquo;ve been able to create systems for &lt;a href=&#34;http://blog.safecast.org/&#34;&gt;measuring the radiation&lt;/a&gt; after a nuclear accident with open source personal Geiger counters. We&amp;rsquo;re also able to strap a &lt;a href=&#34;http://www.mc10inc.com/consumer-products/sports/checklight/&#34;&gt;simple set of sensors&lt;/a&gt; to a child&amp;rsquo;s head in order to better track and understand head injuries in contact sports. These examples &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; are just two of the many that show how data is being intertwined with how we live our lives. This is no more apparent than on the field of professional sports.&lt;/p&gt;

&lt;p&gt;With big money at stake it&amp;rsquo;s no surprise that professional leagues and individual teams are fully embracing the big data craze. Anything and everything &amp;ldquo;for the win&amp;rdquo; has been true for centuries. Now, it&amp;rsquo;s come to include full-time statisticians, data analysts, and, in rare cases (for now), a supercomputer.&lt;/p&gt;

&lt;p&gt;The opening quote atop this piece comes from a recent &lt;a href=&#34;http://gigaom.com/2014/03/10/an-mlb-team-is-apparently-doing-in-game-graph-analysis/&#34;&gt;GigOM article&lt;/a&gt; based on on a piece published by the &lt;a href=&#34;http://www.economist.com/blogs/babbage/2014/03/supercomputers&#34;&gt;Economist&lt;/a&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; that describes a recent purchase of a &lt;a href=&#34;http://www.cray.com/Products/BigData/uRiKA.aspx&#34;&gt;Cray YarcData Urika Data Graph Appliance&lt;/a&gt; by an unnamed Major League Baseball team. From the &lt;a href=&#34;http://www.yarcdata.com/files/product-brief/Urika%20Product%20Brief.pdf&#34;&gt;product brief&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The Urika graph analytics appliance from YarcData is purpose-built to meet these challenging requirements, transforming massive amounts of seemingly unrelated data into relevant insights. [&amp;hellip;] Urika can discover hidden relationships and unknown patterns in Big Data, do it with an unmatched level of speed and simplicity, and facilitate the kinds of breakthroughs that can give your enterprise a measurable competitive advantage&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Why would a baseball team want to have this machine somewhere in the recesses of their stadium? To do real-time in-game analysis of the players and the game. I have no doubt that the unnamed buyer is one of the three teams who have partnered with MLB Advanced Media to install &lt;a href=&#34;http://regressing.deadspin.com/mlb-announces-revolutionary-new-fielding-tracking-syste-1534200504&#34;&gt;a system of high speed cameras&lt;/a&gt; to track, &amp;ldquo;the speed and efficiency of fielders, based on highly accurate readings on hit balls—batted ball speed, launch angle, distance, hang time—and then how fast and how well the defenders react, capturing 30 frames per second on players and 2000 fps on the ball.&amp;rdquo; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; Imagine if you will, a manager being able to interact with live information about the opposing hitter and his history with the current pitcher. What pitches does he typically hit? Miss? Where is he likely to hit a slider with one man on? How far should the left fielder shade towards center? Five feet? Six inches?&lt;/p&gt;

&lt;p&gt;This is the near future of baseball, and more broadly all of professional sports. And to paraphrase Robert Frost, &amp;ldquo;that is making all the difference.&amp;rdquo; A difference that not everyone is comfortable with.&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;What was more difficult for me to grasp was the way that the business of entertainment had really shifted the game and the sport of football in the NFL. The culture of football now is very different from the one I grew up with. When I came up, teammates fought together for wins and got respect for the fight. The player who gave the ball to the referee after a touchdown was commended; the one who played through injury was tough; the role of the blocking tight end was acknowledged; running backs who picked up blitzing linebackers showed heart; &lt;em&gt;and the story of the game was told through the tape, and not the stats alone&lt;/em&gt;. That was my model of football. -Rashard Mendehall, &lt;a href=&#34;http://www.huffingtonpost.com/rashard-mendenhall/rashard-mendenhall-retirement_b_4931316.html&#34;&gt;Huffington Post&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&amp;rsquo;ve seen Moneyball a few times and I&amp;rsquo;ve always enjoyed it. Sure, it&amp;rsquo;s a only movie &lt;em&gt;based&lt;/em&gt; on true events and real people, but I think it&amp;rsquo;s a good example here for the dilemma that&amp;rsquo;s arose due to the creeping in of data in sports. There are a few pivotal scenes where Billy Beane, played wonderfully by Brad Pitt, is trying to make his case to scouts and the Atheltics&amp;rsquo; manager. They were having none of it. In their minds, data couldn&amp;rsquo;t match their experience and intuition, their &amp;ldquo;gut.&amp;rdquo; These fictional conversations are still ongoing out in the world today.&lt;/p&gt;

&lt;p&gt;Simply put, there is a perception that we&amp;rsquo;re losing the humanity by relinquishing control to the overlord of &amp;ldquo;big data.&amp;rdquo; Take Rashard Mendenhall who I quote above. He&amp;rsquo;s in the prime of his career at only 26 years old and playing for a good team. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; On March 9, 2014 he announced his retirement by writing a long piece for the Huffington Post. again, I&amp;rsquo;m probably cherry picking here, but it&amp;rsquo;s hard to mistake his words as a representation of the general feeling among many athletes and their fans. To them, stats and data are not sports, they&amp;rsquo;re cold hard numbers. These types feel that a reliance on data takes away from the joy and the magic of the game. That is reduces spontaneity, and the beauty of the unknown.&lt;/p&gt;

&lt;p&gt;I think they&amp;rsquo;re wrong.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;This past weekend I was lucky to be a guest at a movie premiere. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; The movie, &lt;a href=&#34;http://personal-gold.com/&#34;&gt;Personal Gold&lt;/a&gt;, is a documentary about the 2012 women&amp;rsquo;s track cycling pursuit team that competed at the London Olympics. It was an incredible look at how hard four women pushed themselves to reach beyond their abilities and find that little bit more &lt;em&gt;something&lt;/em&gt;, that extra effort, extra inch, that makes all the difference. However, the movie wasn&amp;rsquo;t your typical Olympic heartwarming tale. A thread that ran through the entire picture was the story of how personal data and intensive physiological tracking helped the riders overcome a limited training staff and budget. Data on their sleep, sunlight exposure, genetic makeup, and their cycling power output was tracked, analyzed, and then used to tweak and fine tune every aspect of their training leading up to the Olympic games. Of course you can look up &lt;a href=&#34;http://www.usacycling.org/us-earns-silver-medal-in-womens-team-pursuit.htm&#34;&gt;the results&lt;/a&gt; to see what happened, or you can just believe me when I tell you that they pulled off something special.&lt;/p&gt;

&lt;p&gt;Data played a major part in their story and how they were able to overcome major adversity. However, data didn&amp;rsquo;t get on the bike and pedal it at over 30MPH for 3 minutes and 17 seconds. It  didn&amp;rsquo;t know, as Sara Hammer recalled during the Q&amp;amp;A after the screening, &amp;ldquo;[..] that I had more in me than I realized. That&amp;rsquo;s what being on a true team is like, having people like Dotsie who know you better than you know yourself.&amp;rdquo;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Humans are funny creatures. We have this massive amazing brain that can invent things like calculus and the Curiosity Rover. But for some reason we take our inventions, like numbers, and label them as inhuman. Cold. Mechanical. But they&amp;rsquo;re just a part of us as anything else we&amp;rsquo;ve birthed into existence with our minds.&lt;/p&gt;

&lt;p&gt;Yes, data is coming into all aspects of sports. Soon we&amp;rsquo;ll be able to watch a football game and see live prediction calculations on who should win. We&amp;rsquo;ll read more articles that are more data visualization than play-by-play reporting. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:6&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:6&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; ESPN has even invested in stats and analysis wundkind, Nate Silver. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:8&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:8&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; And baseball will lead the way, as it always has, into a brave new world of analytics. Does this mean that we&amp;rsquo;ll enjoy it less? See fewer amazing feats of strength and skill? Will be cease to be witness to the beautiful and the inspiring from stadiums, fields, and arenas around the world? No. I think not.&lt;/p&gt;

&lt;p&gt;In the end we&amp;rsquo;re still human. We&amp;rsquo;re prone to mistakes &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:7&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:7&#34;&gt;8&lt;/a&gt;&lt;/sup&gt; and lapses in judgement. We&amp;rsquo;re not perfect machines no matter how many supercomputers we have hidden in our closets. No matter how many high speed cameras are watching a player there is always that chance that they might jump that extra inch a snag that would be home run that had a 100% chance of leaving the field. We haven&amp;rsquo;t yet lost our humanity, our ability to improvise and reach new unknowns, and do what sports does best, inspire awe.&lt;/p&gt;

&lt;p&gt;That is, until the robots enter the draft.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;As always, comments are welcome. This post is available &lt;a href=&#34;https://github.com/erramirez/erramirez.github.io/blob/master/_posts/2014-03-11-the-data-dilemma.md&#34;&gt;on Github&lt;/a&gt; if that’s your style, and &lt;a href=&#34;https://medium.com/p/dd2faba3c00e&#34;&gt;Medium&lt;/a&gt; if you like that platform. Free free to connect with me on &lt;a href=&#34;https://twitter.com/eramirez&#34;&gt;twitter&lt;/a&gt; or &lt;a href=&#34;mailto:er.ramirez@gmail.com&#34;&gt;email&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Cherry-picked, but hey it&amp;rsquo;s my article and I can do what I want.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Welcome to blogging in 2014, but I guess in the end I&amp;rsquo;m no different.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Even with all the negatives associated with Deadspin and the Gawker Empire I&amp;rsquo;m really enjoying their &lt;a href=&#34;http://regressing.deadspin.com/&#34;&gt;Regressing feature section&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;Full disclosure: I grew up in Arizona and consider myself a Cardinals fan. Regardless, they are a &lt;em&gt;good&lt;/em&gt; team.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;I am so LA.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;The New York Times is already &lt;a href=&#34;http://www.nytimes.com/interactive/2012/06/11/sports/basketball/nba-shot-analysis.html&#34;&gt;all over this.&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:6&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:8&#34;&gt;Five Thiry Eight launches March 17th. Can you tell I&amp;rsquo;m excited?
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:8&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;And isn&amp;rsquo;t random error what makes statistics fun anyway?
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:7&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Living With Data</title>
      <link>/post/2014/03/02/living-with-data/</link>
      <pubDate>Sun, 02 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014/03/02/living-with-data/</guid>
      <description>&lt;p&gt;Earlier this week an old friend of mine sent me a message outlining a request. In an effort to get back to his habit of drawing and creating he was reaching to a few of his friends for some inspiration and ideas.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Simple premise. I&amp;rsquo;m inviting important people that I admire, respect, and care about to gift me one creative brief—a specific, attainable objective—to complete by my next birthday.
Example: Some sort of insight as to why people do something, don&amp;rsquo;t do something, or another aspect of human behavior. Think, &amp;ldquo;I want x because y&amp;rdquo;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What follow is slightly edited version of my response. I&amp;rsquo;m sharing it here because a) I too want to be more productive as well b) I want to practice writing and publicly exploring my thoughts and c) sharing is fun.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;As you know, I&amp;rsquo;m very interested and engaged with what it means to live in a world of near ubiquitous personal data. The Quantified Self movement is a key piece of this and we&amp;rsquo;ve seen some amazing work by individuals and institutions (commercial and not). We&amp;rsquo;ve observed that the power that drives real insights can be directly traced to informative data visualizations. However, I feel that we are still in the infancy of what it means to really live with personal data. See &lt;a href=&#34;http://visualized.com/2014/presents/lev-manovich/&#34;&gt;this talk&lt;/a&gt; by Lev Manovich to see how little our data visualization techniques have changed.) (Did you know the bar chart has been around since 1778?)&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;d like to challenge you to explore what it means to Live &lt;em&gt;with&lt;/em&gt; Data. The conversation around QS typically centers around the reduction in autonomy and a move towards algorithmically driven lives (e.g. computers telling us what to do and when to do it based on our personal data). I’ve seen this expressed as Living By Numbers (Data). However, I feel this misses a big piece of the cultural shift. What happens when we Live &lt;em&gt;With&lt;/em&gt; Data as an piece of our human experience? (Some might say that the difference between &amp;ldquo;by&amp;rdquo; and &amp;ldquo;with&amp;rdquo; isn&amp;rsquo;t meaningful, or I&amp;rsquo;m being pedantic. Words have meaning and how we use them is important.) Data can live, breath, and communicate (listen and talk) with us. But, what form does that take?&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;d like to challenge you to explore this idea. Art and creative design can be a big influence on this concept. Here are a few examples of ideas I&amp;rsquo;ve been thinking of lately:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What if the walls in your home were made of LEDs or screens that could reflect your current mood? Would you want it to reflect or change. How? (Thanks to Laurie Frick for prompting this idea during a conversation in her home studio. You should check out her QS based art &lt;a href=&#34;http://www.lauriefrick.com/&#34;&gt;here&lt;/a&gt;.)&lt;/li&gt;
&lt;li&gt;What would it be like if you had physical manifestations of your data in your home or place of business. See &lt;a href=&#34;https://www.newschallenge.org/challenge/healthdata/evaluation/data-experiences-human-scale-3d-bar-graphs-for-environmental-health-data&#34;&gt;this project&lt;/a&gt; from MIT for inspiration.&lt;/li&gt;
&lt;li&gt;Data is typically represented as a direct manifestation of numerical information. Explore ideas of data abstraction. Data as art that tells you a story. This has been explored before with techniques like &lt;a href=&#34;http://en.wikipedia.org/wiki/Chernoff_face&#34;&gt;Chernoff Faces&lt;/a&gt; and more recently with Chloe Fan&amp;rsquo;s &lt;a href=&#34;http://www.sparkvis.com/&#34;&gt;Fitbit Spark visualization&lt;/a&gt;.What if we went further, more abstract and more interactive?&lt;/li&gt;
&lt;li&gt;This one is a little out there so proceed with caution. In the near future robotics and AI might be advanced enough to create actual human replicas or clones. Imagine this happens. What would it be like to create a clone of yourself and stream your personal data to it? Would you test experiments? Would you &lt;a href=&#34;http://en.wikipedia.org/wiki/Agent-based_model&#34;&gt;watch&lt;/a&gt; it (them?) try and learn new things? What data would you not share?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you’ve read this far I’d love to hear what you think. What are the ideas that come to mind when you hear “Living With Data?” I look forward to hearing your thoughts. &lt;/p&gt;

&lt;p&gt;As always, comments are welcome. This post is available &lt;a href=&#34;https://github.com/erramirez/erramirez.github.io/blob/master/_posts/2014-03-02-living-with-data.md&#34;&gt;on Github&lt;/a&gt; if that’s your style, and &lt;a href=&#34;https://medium.com/p/f577b6a8411e&#34;&gt;Medium&lt;/a&gt; if you like that platform. Free free to connect with me on &lt;a href=&#34;https://twitter.com/eramirez&#34;&gt;twitter&lt;/a&gt; or &lt;a href=&#34;mailto:er.ramirez@gmail.com&#34;&gt;email&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>