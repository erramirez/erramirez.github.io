<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Podcasts on Ernesto Ramirez</title>
    <link>/tags/podcasts/index.xml</link>
    <description>Recent content in Podcasts on Ernesto Ramirez</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="/tags/podcasts/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How Much Fun is Maximum Fun?</title>
      <link>/post/2016/06/04/how-much-fun-is-maximum-fun/</link>
      <pubDate>Sat, 04 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016/06/04/how-much-fun-is-maximum-fun/</guid>
      <description>

&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m a big consumer of podcasts. Ever since I started living on my own while in graduate school I&amp;rsquo;ve found that having funny and interesting people in my ears helps me get through the day. Even now that I&amp;rsquo;m cohabiting with my wife I haven&amp;rsquo;t left my trusty podcasts behind. They&amp;rsquo;re great for the long commutes back and forth to San Diego, for reducing my stress while stuck in LA traffic, and for making my laugh while I cook, clean, and exercise.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m a fan and donor (support the things you love!) of one podcast network in particular, &lt;a href=&#34;http://www.maximumfun.org&#34;&gt;Maximum Fun&lt;/a&gt;, so much so that I&amp;rsquo;m a semi-regular participant in their Facebook group and subreddit. Recently, someone in the Facebook group asked for some data about the network, in particular the number of shows that have been published, in order to visualize the growth of the network. As someone who&amp;rsquo;s keen to keep my data analysis skills fresh and nimble I took this as an opportunity to dive back into R. Here&amp;rsquo;s what I&amp;rsquo;ve done so far:&lt;/p&gt;

&lt;h2 id=&#34;gathering-data-from-an-rss-feed&#34;&gt;Gathering Data from an RSS Feed&lt;/h2&gt;

&lt;p&gt;Podcasts are unique in that they&amp;rsquo;re basically just a simple feed of audio files. That feed has data embedded into it that we can access and save. I&amp;rsquo;m pretty new to web-scrapping, but I was able to find a really nice example of &lt;a href=&#34;https://gist.github.com/izahn/5785265&#34;&gt;how to scrape an RSS feed in R here&lt;/a&gt;. I adapted that to scrape and save data from each of the podcasts in the Maximum Fun network. Here&amp;rsquo;s an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(RCurl)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: methods
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: bitops
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(XML)

options(stringsAsFactors = FALSE)

## get rss document
xml.url &amp;lt;- &amp;quot;http://adventurezone.libsyn.com/rss&amp;quot;
script &amp;lt;- getURL(xml.url, ssl.verifypeer = FALSE)

## convert document to XML tree in R
doc &amp;lt;- xmlParse(script)
## find the names of the item nodes

## Extract some information from each node in the rss feed
titles &amp;lt;- xpathSApply(doc,&#39;//item/title&#39;,xmlValue)
date &amp;lt;- xpathSApply(doc,&#39;//item/pubDate&#39;,xmlValue)
duration &amp;lt;- xpathSApply(doc,&#39;//item/itunes:duration&#39;,xmlValue)

# create data frame with important variables
Adventurezone &amp;lt;- data.frame(titles, date, duration)

# create unique identifier
Adventurezone$id &amp;lt;- &amp;quot;The Adventure Zone&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I probably could have created a function to run through all the shows, but instead I used that chunk for every show. It was actually useful as a few of the shows had missing episodes or titles and durations that didn&amp;rsquo;t match up.&lt;/p&gt;

&lt;p&gt;Once I had all the data scrapped from the feeds I was able to combine it into one dataset of 4,202 episodes from 25 different shows. The date/duration variables were pretty messy so I noodled around a bit and cleaned them up into something manageable. I&amp;rsquo;ve saved that final data in &lt;a href=&#34;https://dl.dropboxusercontent.com/u/2513399/MaximumFun.rdata&#34;&gt;Rdata&lt;/a&gt; and &lt;a href=&#34;https://dl.dropboxusercontent.com/u/2513399/MaximumFun.csv&#34;&gt;.csv&lt;/a&gt; formats if you want to play with them yourself. I&amp;rsquo;m loading the RData file here:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;load(url(&amp;quot;https://dl.dropboxusercontent.com/u/2513399/MaximumFun.rdata&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;visualizations&#34;&gt;Visualizations&lt;/h2&gt;

&lt;p&gt;Once we have all the data in a good format creating visualizations is actually pretty easy! Let&amp;rsquo;s start with a simple bar chart that plots the number of shows per month:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
# simple bar chart with sum of number of shows per month
mf.stacked.bar &amp;lt;- ggplot(MaximumFun, aes(monthyear)) + geom_bar() +
  labs(title = &amp;quot;Number of Shows on Maximum Fun per Month&amp;quot;, x = &amp;quot;Year - Month&amp;quot;, y = &amp;quot;Number of Shows Published&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
mf.stacked.bar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-3-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s not bad, but what if we wanted to know which shows were on the network over time? We can use the &amp;ldquo;id&amp;rdquo; variable we created in the initial data scrapping process to label each show. This visualization needs a better color palette to better differentiate between each show, but I&amp;rsquo;ll leave it here for now:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
# add in color to represent the shows
# needs a better color palette
mf.stacked.bar2 &amp;lt;- ggplot(MaximumFun, aes(monthyear, fill = id)) + geom_bar() +
  labs(title = &amp;quot;Number of Shows on Maximum Fun per Month&amp;quot;, x = &amp;quot;Year - Month&amp;quot;, y = &amp;quot;Number of Shows Published&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6), legend.position=&amp;quot;bottom&amp;quot;)
mf.stacked.bar2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-4-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What can we find out about each show? Let&amp;rsquo;s start with visualizing the total number of hours each podcast has published:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
mf.stacked.bar4 &amp;lt;- ggplot(MaximumFun, aes(id, (showlength/60))) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  labs(title = &amp;quot;Total Duration of Each Show on Maximum Fun&amp;quot;, x = &amp;quot;Show&amp;quot;, y = &amp;quot;Total Number of Hours&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
mf.stacked.bar4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-5-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;How about the number of episodes per show?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# simple bar chart for total number of episodes per show
mf.stacked.bar5 &amp;lt;- ggplot(MaximumFun, aes(id)) + geom_bar() +
  labs(title = &amp;quot;Number of Episode of each Show on Maximum Fun&amp;quot;, x = &amp;quot;Show&amp;quot;, y = &amp;quot;Total Number of Episodes&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
mf.stacked.bar5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-6-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I also got around to reformatting the data so that we could look at the number of shows and amount of content produced by Maximum Fun over time. To do that we first have to create a new dataset that aggregates some of the information:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(plyr)
# number of shows on the network over time
MaxFunShows &amp;lt;- ddply(MaximumFun, c(&amp;quot;monthyear&amp;quot;), summarise,
                           &#39;NumberofShows&#39; = length(unique(id)),
                           &#39;DurationofShows&#39; = sum(showlength, na.rm=TRUE)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we can make plots just like the ones we have above!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mf.stacked.bar5 &amp;lt;- ggplot(MaxFunShows, aes(monthyear, NumberofShows)) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  labs(title = &amp;quot;Number of Shows on Maximum Fun over time&amp;quot;, x = &amp;quot;Date&amp;quot;, y = &amp;quot;Number of Shows on the Network&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
mf.stacked.bar5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-8-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-8&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What about the amount of content over time?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mf.stacked.bar5 &amp;lt;- ggplot(MaxFunShows, aes(monthyear, (DurationofShows/60))) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  labs(title = &amp;quot;Amount of Content Produced (in hours) by Maximum Fun over time&amp;quot;, x = &amp;quot;Date&amp;quot;, y = &amp;quot;Hours&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
mf.stacked.bar5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-9-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-9&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, this doesn&amp;rsquo;t include some of the great shows that have moved on to be either independtly operated or part of another network, but it&amp;rsquo;s still a pretty good approximation of the growth over time.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll probably keep noodling around with this data. Probably a lot more I can do with visualizing particular shows and the network as a whole. If you have ideas &lt;a href=&#34;http://twitter.com/eramirez&#34;&gt;get in touch&lt;/a&gt;!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>