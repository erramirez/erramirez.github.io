<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Visualization on Ernesto Ramirez</title>
    <link>/tags/data-visualization/index.xml</link>
    <description>Recent content in Data Visualization on Ernesto Ramirez</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="/tags/data-visualization/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Examining Variability in Longitudinal Physical Activity Datawith R</title>
      <link>/post/2017/09/10/examining-variability-in-physical-activity-data-with-r/</link>
      <pubDate>Sun, 10 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/09/10/examining-variability-in-physical-activity-data-with-r/</guid>
      <description>&lt;div id=&#34;intro&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;As part of my regular work I keep a constant eye on the latest published research that involves the use of Fitbit activity tracking devices. Each new publication is gathered, read (sometimes skimmed), and tagged with appropriate meta-data for our &lt;a href=&#34;https://www.fitabase.com/research-library/&#34;&gt;Fitabase Research Library&lt;/a&gt;. It’s fun work, and it gives me a chance to peak into the every-expanding world of research and clinical use cases for consumer tracking devices and the data they can collect.&lt;/p&gt;
&lt;p&gt;Earlier this summer, while I was traveling to a conference I came across an interesting paper published by a group from the University of South Florida that explored strategies for interpreting highly variable data from long-term use of a Fitbit. I’ll let them explain:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Data Presentation Options to Manage Variability in Physical Activity Research&lt;/em&gt;&lt;br /&gt;
This paper presents seven tactics for managing the variability evident in some physical activity data. High levels of variability in daily step-count data from pedometers or accelerometers can make typical visual inspection difficult. Therefore, the purpose of the current paper is to discuss several strategies that might facilitate the visual interpretation of highly variable data. The seven strategies discussed in this paper are phase mean and median lines, daily average per week, weekly cumulative, proportion of baseline, 7-day moving average, change point detection, and confidence intervals. We apply each strategy to a data set and discuss the advantages and disadvantages. &lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1002/jaba.397/abstract&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It’s an interesting paper, with some general, easy-to-use, methods of visualizing daily-scale time series data. While reading it, I got to thinking that all of the methods they explored should be able to be easily reproducible in R. Being a sucker for practicing my R skills I set out to create some reproducible examples of each method with my own Fitbit data. A few cross-country flights later I think I’ve done a decent enough job. Let’s jump in!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;. The data referenced below is available on Github (as you’ll see in the &lt;code&gt;read_csv&lt;/code&gt; call). I invite you to use it so you can follow along with the examples below.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-eight-visualization-methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Eight Visualization Methods&lt;/h2&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Data&lt;/h3&gt;
&lt;p&gt;In the paper, they use approximately 180 days of daily step data from a Fitbit One that was worn by a participant in a previous study. It’s important to note that this data comes from an intervention study, with three phases: baseline, intervention phase 1, and intervention phase 2. Now, we don’t have access to their participant’s data, so I set out to use my own. Using our Fitabase platform I exported one year of daily step data, from 2016-05-12 to 2017-05-11. I also applied somewhat arbitrary cutoffs for the three phases: 30 days for “baseline”, 135 days for “intervention 1”, and 200 days for “intervention 2”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(scales)
library(ggthemes)
library(lubridate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Load data 
# format date when loading in
Daily_Steps &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/erramirez/datascience/master/sevenways/dailySteps_20160512_20170511.csv&amp;quot;, 
   col_types = cols(
    ActivityDay= col_date(&amp;quot;%m/%d/%Y&amp;quot;), 
    StepTotal = col_integer()))

# create a day variable to number the observations by day
# used first day as &amp;quot;1&amp;quot; instead of zero
# add a observation variable with three periods
# Day 1 - 30  = baseline
# Day 31 - 165 = intervention 1
# Day 195 - 365 = intervention 2
startdate &amp;lt;- min(Daily_Steps$ActivityDay)

Daily_Steps &amp;lt;- Daily_Steps %&amp;gt;% 
  mutate(days = as.numeric(difftime(ActivityDay, startdate, units = &amp;quot;days&amp;quot;) + 1),
         observation = as.factor(case_when(days &amp;lt;= 30 ~&amp;quot;Baseline&amp;quot;,
                                           days &amp;lt; 195 ~ &amp;quot;Intervention 1&amp;quot;,
                                           days &amp;lt;= 365 ~ &amp;quot;Intervention 2&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;daily-steps&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;1. Daily Steps&lt;/h3&gt;
&lt;p&gt;Pretty simple here, let’s just visualize the daily steps taken with days along the &lt;em&gt;x&lt;/em&gt;-axis and total steps on the &lt;em&gt;y&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In this plot, and the plots that follow I attempted to use similar formatting to what was presented in the article. They’re pretty minimal so I went with &lt;code&gt;theme_tufte&lt;/code&gt; from the excellent &lt;a href=&#34;https://github.com/jrnold/ggthemes&#34;&gt;ggthemes package&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# generate a line+points plot to show one year of daily step data
# add some formatting to match journal article 

daily_steps_plot &amp;lt;- ggplot(Daily_Steps, aes(days, StepTotal)) +
  geom_line(size = .35) +
  geom_point() +
  scale_x_continuous(breaks = seq(0,365,20), expand = c(.01, .01)) +
  scale_y_continuous(breaks = seq(0,35000,5000), limits = c(0,38000)) +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) +
  labs(title = &amp;quot;Daily Steps&amp;quot;, 
       x = &amp;quot;DAYS&amp;quot;, 
       y = &amp;quot;STEPS&amp;quot;) +
  geom_vline(xintercept = c(30.5, 195.5)) +
  annotate(&amp;quot;text&amp;quot;, x = c(15, 112.5, 277.5), y = 38000, 
           label = c(&amp;quot;BL&amp;quot;, &amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;))

daily_steps_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/dailysteps-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;phase-mean-and-phase-median-lines&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;2. Phase Mean and Phase Median Lines&lt;/h3&gt;
&lt;p&gt;This was also pretty simple. To better understand how the daily steps varied from the mean and median values for each observation period (baseline, intervention 1, intervention 2) we can use &lt;code&gt;group_by&lt;/code&gt; and &lt;code&gt;summarise&lt;/code&gt; to easily calculate the mean and median and plug those values into &lt;code&gt;geom_segment&lt;/code&gt; in order to plot three separate lines with the correct start and end dates.&lt;/p&gt;
&lt;p&gt;This method of creating an additional data set to use in conjunction with &lt;code&gt;geom_segment&lt;/code&gt; will be useful throughout the remainder to of the visualizations we go over here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create data sets for mean/median grouped by observation period
# also add start and stop days per observation period

observation_data &amp;lt;- Daily_Steps %&amp;gt;% 
  group_by(observation) %&amp;gt;% 
  summarise(mean = mean(StepTotal),
            median = median(StepTotal),
            start = min(days), 
            end = max(days))

# create a plot with mean steps per day per observation period
# uses geom_segment and observation_data to draw mean lines

phase_mean_plot &amp;lt;- ggplot(Daily_Steps, aes(days, StepTotal)) +
  geom_line(size = .35) +
  geom_point() +
  scale_x_continuous(breaks = seq(0,365,20), expand = c(.01, .01)) +
  scale_y_continuous(breaks = seq(0,35000,5000), limits = c(0,35000)) +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) +
  labs(title = &amp;quot;Daily Steps&amp;quot;,
       subtitle = &amp;quot;With Mean Steps per Day per Observation Period&amp;quot;,
       x = &amp;quot;DAYS&amp;quot;, 
       y = &amp;quot;STEPS&amp;quot;) +
  geom_vline(xintercept = c(30, 195)) +
  annotate(&amp;quot;text&amp;quot;, x = c(15, 112.5, 277.5),
           y = 34000, 
           label = c(&amp;quot;BL&amp;quot;, &amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;)) +
  geom_segment(aes(x = start, y = mean, xend = end, yend = mean), data = observation_data)

phase_mean_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/phase_means-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a plot with median steps per day per observation period
# uses geom_segment and observation_data to draw median lines

phase_median_plot &amp;lt;- ggplot(Daily_Steps, aes(days, StepTotal)) + 
  geom_line(size = .35) +
  geom_point() +
  scale_x_continuous(breaks = seq(0,365,20), expand = c(.01, .01)) +
  scale_y_continuous(breaks = seq(0,35000,5000), limits = c(0,35000)) +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) +
  labs(title = &amp;quot;Daily Steps&amp;quot;,
       subtitle = &amp;quot;With Median Steps per Day per Observation Period&amp;quot;,
       x = &amp;quot;DAYS&amp;quot;, 
       y = &amp;quot;STEPS&amp;quot;) +
  geom_vline(xintercept = c(30, 195)) +
  annotate(&amp;quot;text&amp;quot;, x = c(15, 112.5, 277.5),
           y = 34000, 
           label = c(&amp;quot;BL&amp;quot;, &amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;)) +
  geom_segment(aes(x = start, y = median, xend = end, yend = median), data = observation_data)
  
phase_median_plot  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/phase_medians-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;daily-average-per-week-and-weekly-median&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;3. Daily Average per Week and Weekly Median&lt;/h3&gt;
&lt;p&gt;Now things start to get interesting! Understanding the variability at longer time scale is a nice way to better understand how activity changes over longer periods of time. In this example, we’re reducing the daily variability to weekly variability by calculating the mean and median steps per day for each week in the data set.&lt;/p&gt;
&lt;p&gt;While this seems easy, there are some choices we have to make here. Primarily, what is a week? Is a calendar week? Is it just seven consecutive days? If it’s a calendar week, does is start or end on Sunday? What happens when a week transverses an study phase transition?&lt;/p&gt;
&lt;p&gt;For ease of creating reusable examples we can actually explore how to derive a “week” using two definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Monday-Sunday seven-day week&lt;/li&gt;
&lt;li&gt;A running seven-day week, regardless of day of the week&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this first method, we use &lt;code&gt;isoweek&lt;/code&gt; from the &lt;code&gt;lubridate&lt;/code&gt; package to find the week number based on a Monday-Sunday week. Keep in mind that our data spans both 2016 and 2017, so the resulting &lt;em&gt;week&lt;/em&gt; variable will repeat and return the same value for the beginning and ending observations since the data doesn’t start on a Monday. I also wanted to create a variable, &lt;em&gt;weeknum&lt;/em&gt;, that reflected the number of weeks elapsed. Last week I was exploring how to calculate streaks in data, and stumbled upon &lt;a href=&#34;https://stackoverflow.com/questions/1502910/how-can-i-count-runs-in-a-sequence&#34;&gt;a great comment stackoverflow&lt;/a&gt; about numbering runs in a series. I applied that here, and started &lt;em&gt;weeknum&lt;/em&gt; at 1 instead of 0.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create week variable based on isoweek
# create weenum variable for running week number as weeknum restarts at begining of the year
Daily_Steps &amp;lt;- Daily_Steps %&amp;gt;% 
  mutate(week = isoweek(Daily_Steps$ActivityDay),
         weeknum = c(0,cumsum(week[-1L] != week[-length(week)]))+1
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the second method, wanted to explore how to set a week as seven consecutive daily observations regardless of the day of the week. I had some old code I used during my dissertation that I was able to re-use here. It’s not pretty and could probably be updated to make use of tidyverse principles, but it works for now. &lt;em&gt;(Tips/ideas on how to improve this section are welcomed!)&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# function to create data frame of length: 7 observations
weekwindow &amp;lt;- function(x) {
  week &amp;lt;- x[n:(n+6),]
  return(week)
} 

# initialize n to value 1
n &amp;lt;- 1

#create empty list
Daily_Steps_list &amp;lt;- list()

#loop through data and append 7-day moving windows to the list
for (i in 1:53) { #set length of function to 1:number of weeks in the data set
  df &amp;lt;- weekwindow(Daily_Steps) #create a new dataframe based on weekwindow function
  df$dayreg &amp;lt;- c(1:nrow(df)) #create a new variable and set to the day in the 7-day window (1:7)
  df$week &amp;lt;- i #create a new variable and set to the value of i; gives week number
  Daily_Steps_list[[i]] &amp;lt;- df #adds the dataframe (df) to the empty list previously set
  n &amp;lt;- n+7 #increments n by 7 so weeknumber function calls next 7 days. 
} 

# combine all 7-day/week data frames in week.list into a single dataframe
# get rid of trailing NA entries from week 53
Daily_Steps_7DayWeek &amp;lt;- bind_rows(Daily_Steps_list) %&amp;gt;% 
  filter(ActivityDay &amp;lt;= &amp;quot;2017-05-11&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now, we have two data sets that reflect two different ways to explore weeks in our data. Now comes the fun part - visualizing it! I personally like calendar weeks (isoweek / method one above), as they make conceptual sense when we’re talking about dates so I’ll use that data as the basis for creating the plots. First, we have to create the summarized data set so we have the daily mean, median and standard deviation per week. We do have to keep in mind here that not all weeks will have seven days as obervations may have started/ended in the middle of a week (in this data week 1 only has 4 days).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# summarize data by week number
# append observation variable to summarized weekly data
# Baseline = Weeks 1-5
# Intervention 1 = Weeks 6-28
# Intervention 2 = Weeks 29-53
Mean_Median_Week &amp;lt;- Daily_Steps %&amp;gt;%  
  group_by(weeknum) %&amp;gt;% 
  summarise(mean = mean(StepTotal),
            median = median(StepTotal),
            sd = sd(StepTotal)) %&amp;gt;% 
  mutate(observation = case_when(weeknum &amp;lt;= 5 ~ &amp;quot;Baseline&amp;quot;,
                                 weeknum &amp;lt;= 28 ~ &amp;quot;Intervention 1&amp;quot;,
                                 weeknum &amp;lt;= 53 ~ &amp;quot;Intervention 2&amp;quot;)
         )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can plot. We’ll use a good deal of the code we used in the previous plots here. However, note that we’re grouping by the observation so that we have distinct series visualized in the plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot the mean week with standard deviation error bars
# seperate the oberservation periods using geom_vline
Mean_Week &amp;lt;- ggplot(Mean_Median_Week, aes(weeknum, mean, group = observation)) + 
  geom_point() +
  geom_line() +
  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd), width = .5) +
  scale_x_continuous(breaks = seq(0,53,1), limits = c(0,53), expand = c(.01, .01)) +
  scale_y_continuous(breaks = seq(0,28000,2000), limits = c(0,28000)) +
  #theme_tufte() +
  #geom_rangeframe() +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) +
  labs(title = &amp;quot;Daily Average Steps per Week&amp;quot;,
       x = &amp;quot;WEEKS&amp;quot;, 
       y = &amp;quot;AVERAGE DAILY STEPS&amp;quot;,
       caption = &amp;quot;Note: Error bars depict the standard deviation of the mean.&amp;quot;) +
  geom_vline(xintercept = c(5.5, 28.5)) +
  annotate(&amp;quot;text&amp;quot;, x = c(2.25, 16, 42),
           y = 25000, 
           label = c(&amp;quot;BL&amp;quot;, &amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;))

Mean_Week&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/mean_week_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot the median step counts per week
Median_Week &amp;lt;- ggplot(Mean_Median_Week, aes(weeknum, median, group = observation)) + 
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = seq(0,53,1), limits = c(0,53), expand = c(.01, .01)) +
  scale_y_continuous(breaks = seq(0,19000,2000), limits = c(0,19000)) +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) +
  labs(title = &amp;quot;Median Daily Steps per Week&amp;quot;,
       x = &amp;quot;WEEKS&amp;quot;, 
       y = &amp;quot;MEDIAN DAILY STEPS&amp;quot;) +
  geom_vline(xintercept = c(5.5, 28.5)) +
annotate(&amp;quot;text&amp;quot;, x = c(2.25, 16, 42),
           y = 18000, 
           label = c(&amp;quot;BL&amp;quot;, &amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;))
Median_Week&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/median_week_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;weekly-cumulative&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;4. Weekly Cumulative&lt;/h3&gt;
&lt;p&gt;This is actually one of the easier visualizations as we can make use of our previously calculated &lt;em&gt;weeknum&lt;/em&gt; to calculate the weekly cumulative sum.&lt;/p&gt;
&lt;p&gt;Why would weekly cumulative sums be interesting? Well, many interventions may focus on the weekly total steps (10,000 per day is 70,000 per week), and this plot can quickly show you when those weekly goals are met. This type of visualization also provides a way to see day-to-day variation and week-to-week variation in activity within one plot. By quickly glancing at the vertical space between linked data points one can see if there are days of either outstanding activity, or lack there of.&lt;/p&gt;
&lt;p&gt;You can also see here that the week 1 observation started on a Thursday as there are only four days of observation for week 1 (and again for week 53).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# first create a new data set with an new variable that has the weekly cumulative sum of StepTotal
Daily_Steps_Week_Cumulative &amp;lt;- Daily_Steps %&amp;gt;% 
  group_by(weeknum) %&amp;gt;% 
  mutate(cs = cumsum(StepTotal))

# create plot of the weekly cumulative steps
# each line is a week using group = weeknum

Weekly_Cumulative &amp;lt;- ggplot(Daily_Steps_Week_Cumulative, aes(days, cs, group = weeknum)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = seq(0,365,20), expand = c(.01, .01)) +
  scale_y_continuous(breaks = seq(0,120000,20000)) +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) +
  labs(title = &amp;quot;Weekly Cumulative Steps&amp;quot;, 
       x = &amp;quot;DAYS&amp;quot;, 
       y = &amp;quot;STEPS&amp;quot;) +
  geom_vline(xintercept = c(32.5, 193.5)) +
  annotate(&amp;quot;text&amp;quot;, x = c(15, 112.5, 277.5), y = 130000, 
           label = c(&amp;quot;BL&amp;quot;, &amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;))

Weekly_Cumulative&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/weekly_cumulative-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;proportion-of-baseline-mean-and-proportion-of-baseline-median&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5. Proportion of Baseline Mean and Proportion of Baseline Median&lt;/h3&gt;
&lt;p&gt;In these visualizations we want to see how daily steps compared to the the mean and median of the baseline value. First we create a small data setbased on our previously created &lt;code&gt;observation_data&lt;/code&gt; (see Phase Mean/Median above) that contains our baseline mean and median value, and then create our proportion data sets. After that straightforward process it’s relatively simple to generate the plots using much of the same code we’ve used previously. We also use the “end” of the baseline phase (in number of days) to create a new “days” variable so that the Intervention 1 phase starts at “day 1”.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;. I had some trouble figuring out how to properly apply a logarithmic scale to the y-axis, but a quick trip in to Stack Overflow helped me find &lt;code&gt;scale_y_log10&lt;/code&gt; and use it here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a dataframe of just data from the &amp;quot;baseline&amp;quot; phase
baseline_values &amp;lt;- observation_data %&amp;gt;% 
  filter(observation == &amp;quot;Baseline&amp;quot;)

# create a dataframe of daily proportions for &amp;quot;intervention 1&amp;quot; and &amp;quot;intervention 2&amp;quot; phases
# use the end of baseline (in days) to create new days2 variable to start &amp;quot;intervention 1&amp;quot; at day 1
proportions &amp;lt;- Daily_Steps %&amp;gt;% 
  filter(observation != &amp;quot;Baseline&amp;quot;) %&amp;gt;% 
  mutate(proportion_mean = (StepTotal / baseline_values$mean),
         proportion_median = (StepTotal / baseline_values$median),
         days2 = (days - baseline_values$end))

# create mean and medians of the proportions within each phase
# also creat start/end days for use with geom_segment to create start/stop points for horizontal lines
proportions_mean_median &amp;lt;- proportions %&amp;gt;% 
  group_by(observation) %&amp;gt;% 
  summarize(mean = mean(proportion_mean),
            median = median(proportion_median),
            start = min(days2), 
            end = max(days2))

# separate &amp;quot;intervention 1&amp;quot;  data into a dataframe for use in geom_segment
proportion_intervention1_data&amp;lt;- proportions_mean_median %&amp;gt;% 
  filter(observation == &amp;quot;Intervention 1&amp;quot;)

# separate &amp;quot;intervention 2&amp;quot;  data into a dataframe for use in geom_segment
proportion_intervention2_data&amp;lt;- proportions_mean_median %&amp;gt;% 
  filter(observation == &amp;quot;Intervention 2&amp;quot;)

# create mean proportion plot
# use scale_y_log10 and annotation_logticks to try and match original paper visualization
Proportion_Mean_Plot &amp;lt;- ggplot(proportions, aes(days2, proportion_mean, group = observation)) +
  geom_line() +
  geom_point(aes(shape = observation)) + 
  scale_shape_manual(values=c(16,0)) +
  scale_x_continuous(breaks = seq(0,335,20), expand = c(.01, .01)) +
  scale_y_log10(breaks = c(0.1, 1, 10), limits = c(0.1, 10)) +
  annotation_logticks(sides = &amp;quot;l&amp;quot;) +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) + 
  theme(legend.position=&amp;quot;none&amp;quot;) +
  labs(title = &amp;quot;Proportion of Baseline Mean&amp;quot;,
       subtitle = &amp;quot;Daily steps within each intervention phase&amp;quot;,
       x = &amp;quot;DAYS WITHIN PHASE&amp;quot;, 
       y = &amp;quot;PROPORTION OF BASELINE \n(MEAN)&amp;quot;) +
  geom_vline(xintercept = 164.5) +
  geom_hline(yintercept = 1) +
  annotate(&amp;quot;text&amp;quot;, x = c(82, 246), y = 10,
           label = c(&amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;)) +
  geom_segment(aes(x = 0, y = mean, xend = end, yend = mean),
               data = proportion_intervention1_data) +
  geom_segment(aes(x = start, y = mean, xend = end, yend = mean),
               data = proportion_intervention2_data, linetype = 3) 

Proportion_Mean_Plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/proportion_mean_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create median proportion plot
# use scale_y_log10 and annotation_logticks to try and match original paper visualization
Proportion_Median_Plot &amp;lt;- ggplot(proportions, aes(days2, proportion_median, group = observation)) +
  geom_point(aes(shape = observation)) + 
  scale_shape_manual(values=c(16,0)) +
  geom_line() +
  scale_x_continuous(breaks = seq(0,335,20), expand = c(.01, .01)) +
  scale_y_log10(breaks = c(0.1, 1, 10), limits = c(0.1, 10)) +
  annotation_logticks(sides = &amp;quot;l&amp;quot;) +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) +
  theme(legend.position=&amp;quot;none&amp;quot;) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  labs(title = &amp;quot;Proportion of Baseline Median&amp;quot;,
       subtitle = &amp;quot;Daily steps within each intervention phase&amp;quot;,
       x = &amp;quot;DAYS WITHIN PHASE&amp;quot;, 
       y = &amp;quot;PROPORTION OF BASELINE \n(MEDIAN)&amp;quot;) +
  geom_vline(xintercept = 164.5) +
  geom_hline(yintercept = 1) +
  annotate(&amp;quot;text&amp;quot;, x = c(82, 246), y = 10,
           label = c(&amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;)) +
  geom_segment(aes(x = 0, y = median, xend = end, yend = median),
               data = proportion_intervention1_data, linetype = 2) +
  geom_segment(aes(x = start, y = median, xend = end, yend = median),
               data = proportion_intervention2_data, linetype = 3)

Proportion_Median_Plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/proportion_median_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;day-moving-average&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;6. 7-Day Moving Average&lt;/h3&gt;
&lt;p&gt;The 7-day moving average is one of my favorite methods for visualizing trends in messy highly variable time series data. As the authors of the paper noted, the running average method reduces variability, but it makes spotting those important trends much easier.&lt;/p&gt;
&lt;p&gt;To calculate the 7-day average we can use the &lt;code&gt;zoo&lt;/code&gt; package and it’s &lt;code&gt;rollmean&lt;/code&gt; function. Note that doing so automatically will remove the first 6 days of each phase as the seventh day in each phase is the first to have a true 7-day mean value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install zoo package if not already installed
# install.packages(&amp;quot;zoo&amp;quot;)

# load zoo package
library(zoo)

# create 7-day average data set
# we only want rolling 7-day within each observation so we use group_by first
Daily_Steps_7DMAV &amp;lt;- Daily_Steps %&amp;gt;% 
  group_by(observation) %&amp;gt;% 
  mutate(sevenmav = rollmean(StepTotal, 7, fill = NA, align = &amp;quot;right&amp;quot;))

# plot the 7-day moving average
movingavg_plot &amp;lt;- ggplot(Daily_Steps_7DMAV, aes(days, sevenmav)) +
  geom_line(size = .35) +
  geom_point() +
  scale_x_continuous(breaks = seq(0,365,20), expand = c(.01, .01)) +
  scale_y_continuous(breaks = seq(0,35000,5000), limits = c(0,35000)) +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) +
  labs(title = &amp;quot;7-Day Moving Average&amp;quot;, 
       x = &amp;quot;DAYS&amp;quot;, 
       y = &amp;quot;STEPS (MOVING AVERAGE)&amp;quot;) +
  geom_vline(xintercept = c(30.5, 195.5)) +
  annotate(&amp;quot;text&amp;quot;, x = c(15, 112.5, 277.5), y = 38000, label = c(&amp;quot;BL&amp;quot;, &amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;))

movingavg_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/movingavg-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;confidence-intervals&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;7. Confidence Intervals&lt;/h3&gt;
&lt;p&gt;This is where my statistical knowledge begins to falter, but by relying on the methodology in the paper I was able to recreate their process for creating confidence intervals.&lt;/p&gt;
&lt;p&gt;I used the freely available SMA application from &lt;a href=&#34;http://clinicalresearcher.org/software.htm&#34;&gt;clinicalresearcher.org&lt;/a&gt; (as reference in the paper) to run the bootstrapping procedure to produce the confidence intervals. It’s important to note that the authors decided to reduce the number of data points to only the last 28 days of each phase (84 total days) in their analysis as the SMA software states that their bootstrapping method is primarily for “analyzing short streams (n&amp;lt;30 per phase) of auto-correlated time-series data.” I replicated that procedure here as well. The resulting upper and lower bounds for the 95% confidence interval were then plotted. As you can see here in the plot, there is a significant difference between the &lt;em&gt;Baseline&lt;/em&gt; phase and &lt;em&gt;Intervention 1&lt;/em&gt; and the &lt;em&gt;Baseline&lt;/em&gt; phase and &lt;em&gt;Intervention 2&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create new data sets that only include the last 28 days of each phase.
Baseline_28 &amp;lt;-  Daily_Steps %&amp;gt;% 
  filter(observation == &amp;quot;Baseline&amp;quot;, 
         days &amp;gt; 2)
Intervention1_28 &amp;lt;- Daily_Steps %&amp;gt;% 
  filter(observation == &amp;quot;Intervention 1&amp;quot;,
         days &amp;gt; (194-28))
Intervention2_28 &amp;lt;- Daily_Steps %&amp;gt;% 
  filter(observation == &amp;quot;Intervention 2&amp;quot;,
         days &amp;gt; (365-28))

# bind all those 28-day data sets together and export it as a CSV to use in SMA application. 
SMA_Data &amp;lt;- bind_rows(Baseline_28, Intervention1_28, Intervention2_28)
write_csv(SMA_Data, &amp;quot;~/Downloads/SMA_Data.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After copying the “last 28” days data into the SMA application and setting the number of iterations to 20,000, the resulting output is saved as a .txt file. You can access that &lt;a href=&#34;https://github.com/erramirez/datascience/blob/master/sevenways/SMA_Data_Output.txt&#34;&gt;output here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can then take those 95% CI values from the oputput for each phase and add them to the observation_date data set we created for the phase means/medians plots. Then we append those values to the full Daily_Steps data set and plot it!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add 95% CI values as lowe/upper CI variables
observation_data$lowerCI &amp;lt;- c(7211.57, 11247.89, 12070.50)
observation_data$upperCI &amp;lt;- c(9480.32, 14303.11, 15935.50)

# append the CI values to the full Daily_Steps data set
Daily_Steps_CI &amp;lt;- Daily_Steps %&amp;gt;% left_join(., observation_data)

# plot the 95% CI using combination of geom_segment (for lower/upper CI lines) and geom_ribbon (for shadding)
CI_plot &amp;lt;- ggplot(Daily_Steps_CI, aes(days, StepTotal)) +
  geom_line(size = .35) +
  geom_point() +
  scale_x_continuous(breaks = seq(0,365,20), expand = c(.01, .01)) +
  scale_y_continuous(breaks = seq(0,35000,5000)) +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) +
  labs(title = &amp;quot;Daily Steps&amp;quot;,
       subtitle = &amp;quot;With 95% confidence interval&amp;quot;,
       x = &amp;quot;DAYS&amp;quot;, 
       y = &amp;quot;STEPS&amp;quot;) +
  geom_vline(xintercept = c(30, 195)) +
  annotate(&amp;quot;text&amp;quot;, x = c(15, 112.5, 277.5),
           y = 38000, 
           label = c(&amp;quot;BL&amp;quot;, &amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;)) +
  geom_segment(aes(x = start, y = lowerCI, xend = end, yend = lowerCI), data = observation_data, linetype = 2) +
  geom_segment(aes(x = start, y = upperCI, xend = end, yend = upperCI), data = observation_data, linetype = 2) +
  geom_ribbon(aes(ymin = lowerCI, ymax = upperCI), alpha = .2)

CI_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/CI_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;change-point-detection&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;8. Change-point Detection&lt;/h3&gt;
&lt;p&gt;Change-point detection is a very interesting method for determining when significant changes occur in time series data. Here we use the &lt;code&gt;changepoint&lt;/code&gt; package and the &lt;code&gt;cpt.mean&lt;/code&gt; function to detect the significant changes in the mean. The authors use &lt;em&gt;binnary segmentation&lt;/em&gt; and limit the number of detectable change points to be equal to the number of phase changes (2), and I apply the same methods here. We then plot those changes with horizontal dashed lines that represent the mean values for each detected significant state. I also include the default changepoint plot here for comparison.&lt;/p&gt;
&lt;p&gt;Unsurpisingly, we don’t see any agreement with the observed changepoints as determined by the analysis and the phase changes. This is due to the arbritrary definition of our phases here, but that is not to say this changepoint method is without merit. With a “real” obsered baseline/invtervention one could use this simple analtyical technique and quick visualization to see if changes in intervention(s) actually makes a significant difference in the outcome.&lt;/p&gt;
&lt;p&gt;I’ll also noted, that one of the more interesting uses of changepoint detection is to run this analysis “live” on data as it is created, thus being able to have a more automated way to understand significant changes in outcomes as you’re measuring them. Something that may be useful for just-in-time interventions or more personalized measurement studies. I found &lt;a href=&#34;https://blog.twitter.com/engineering/en_us/a/2014/breakout-detection-in-the-wild.html&#34;&gt;this blog post from the Twitter engineering group&lt;/a&gt; to be very helpful when I was wrapping my head around this methodology.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;changepoint&amp;quot;)
library(changepoint)

# create a changepoint opject using the cpt.mean function with the parameters used in the paper
change &amp;lt;- cpt.mean(Daily_Steps$StepTotal, method=&amp;quot;BinSeg&amp;quot;, Q=2)
plot(change) # the default changepoint plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/changepoint-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;change&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Class &amp;#39;cpt&amp;#39; : Changepoint Object
##        ~~   : S4 class containing 14 slots with names
##               cpts.full pen.value.full data.set cpttype method test.stat pen.type pen.value minseglen cpts ncpts.max param.est date version 
## 
## Created on  : Fri Apr 21 18:46:22 2017 
## 
## summary(.)  :
## ----------
## Created Using changepoint version 2.2.2 
## Changepoint type      : Change in mean 
## Method of analysis    : BinSeg 
## Test Statistic  : Normal 
## Type of penalty       : MBIC with value, 17.69969 
## Minimum Segment Length : 1 
## Maximum no. of cpts   : 2 
## Changepoint Locations : 94 331 
## Range of segmentations:
##      [,1] [,2]
## [1,]   94   NA
## [2,]   94  331
## 
##  For penalty values: 509315501 202651677&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add a changepoint variable based on the output of the changepoint analysis
Daily_Steps &amp;lt;- Daily_Steps %&amp;gt;% 
  mutate(changepoints = case_when(days &amp;lt;= 94 ~ 1,
                                  days &amp;lt;= 331 ~ 2,
                                  days &amp;gt; 331 ~ 3))

# create a data set of mean values for each change point to be used with geom_segment in the plot
change_means &amp;lt;- Daily_Steps %&amp;gt;% 
  group_by(changepoints) %&amp;gt;% 
  summarize(mean = mean(StepTotal),
         start = min(days),
         end = max(days))

# plot it!
changepoint_plot &amp;lt;- ggplot(Daily_Steps, aes(days, StepTotal)) +
  geom_line(size = .35) +
  geom_point() +
  scale_x_continuous(breaks = seq(0,365,20), expand = c(.01, .01)) +
  scale_y_continuous(breaks = seq(0,35000,5000), limits = c(0,35000)) +
  theme_bw() + 
  theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), axis.line = element_line(colour = &amp;quot;black&amp;quot;)) +
  theme(axis.line.x = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1),
        axis.line.y = element_line(colour = &amp;quot;black&amp;quot;, size = 0.5, linetype = 1)) +
  theme(axis.text.x = element_text(size = 6)) +
  labs(title = &amp;quot;Daily Steps&amp;quot;,
       subtitle = &amp;quot;With detected change points&amp;quot;,
       x = &amp;quot;DAYS&amp;quot;, 
       y = &amp;quot;STEPS&amp;quot;) +
  geom_vline(xintercept = c(30, 195)) +
  annotate(&amp;quot;text&amp;quot;, x = c(15, 112.5, 277.5),
           y = 38000, 
           label = c(&amp;quot;BL&amp;quot;, &amp;quot;Intervention 1&amp;quot;, &amp;quot;Intervention 2&amp;quot;)) +
  geom_segment(aes(x = start, y = mean, xend = end, yend = mean), data = change_means, linetype = 2) 

changepoint_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-09-10-examining-variability-in-phsyical-activity-with-r_files/figure-html/changepoint-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;wrapping-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;Well, that was fun! I know I learned a lot more about using ggplot, and some anaytical methods, that can be used for examining time series data. I’m lucky to have &lt;em&gt;a lot&lt;/em&gt; of time series data at my disposal to play around with these visualization methods and I hope this can be useful for you as well.&lt;/p&gt;
&lt;p&gt;More broadly, I hope this this just another gentle push for our research community to share more code and examples alongside their published work. Sharing is caring folks!&lt;/p&gt;
&lt;p&gt;As always, comments and edits are welcome. Feel free to submit a pull request or issue on Github, or just &lt;a href=&#34;http://www.twitter.com/eramriez&#34;&gt;ping me on twitter&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How Much Fun is Maximum Fun?</title>
      <link>/post/2016/06/04/how-much-fun-is-maximum-fun/</link>
      <pubDate>Sat, 04 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016/06/04/how-much-fun-is-maximum-fun/</guid>
      <description>

&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m a big consumer of podcasts. Ever since I started living on my own while in graduate school I&amp;rsquo;ve found that having funny and interesting people in my ears helps me get through the day. Even now that I&amp;rsquo;m cohabiting with my wife I haven&amp;rsquo;t left my trusty podcasts behind. They&amp;rsquo;re great for the long commutes back and forth to San Diego, for reducing my stress while stuck in LA traffic, and for making my laugh while I cook, clean, and exercise.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m a fan and donor (support the things you love!) of one podcast network in particular, &lt;a href=&#34;http://www.maximumfun.org&#34;&gt;Maximum Fun&lt;/a&gt;, so much so that I&amp;rsquo;m a semi-regular participant in their Facebook group and subreddit. Recently, someone in the Facebook group asked for some data about the network, in particular the number of shows that have been published, in order to visualize the growth of the network. As someone who&amp;rsquo;s keen to keep my data analysis skills fresh and nimble I took this as an opportunity to dive back into R. Here&amp;rsquo;s what I&amp;rsquo;ve done so far:&lt;/p&gt;

&lt;h2 id=&#34;gathering-data-from-an-rss-feed&#34;&gt;Gathering Data from an RSS Feed&lt;/h2&gt;

&lt;p&gt;Podcasts are unique in that they&amp;rsquo;re basically just a simple feed of audio files. That feed has data embedded into it that we can access and save. I&amp;rsquo;m pretty new to web-scrapping, but I was able to find a really nice example of &lt;a href=&#34;https://gist.github.com/izahn/5785265&#34;&gt;how to scrape an RSS feed in R here&lt;/a&gt;. I adapted that to scrape and save data from each of the podcasts in the Maximum Fun network. Here&amp;rsquo;s an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(RCurl)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: methods
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: bitops
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(XML)

options(stringsAsFactors = FALSE)

## get rss document
xml.url &amp;lt;- &amp;quot;http://adventurezone.libsyn.com/rss&amp;quot;
script &amp;lt;- getURL(xml.url, ssl.verifypeer = FALSE)

## convert document to XML tree in R
doc &amp;lt;- xmlParse(script)
## find the names of the item nodes

## Extract some information from each node in the rss feed
titles &amp;lt;- xpathSApply(doc,&#39;//item/title&#39;,xmlValue)
date &amp;lt;- xpathSApply(doc,&#39;//item/pubDate&#39;,xmlValue)
duration &amp;lt;- xpathSApply(doc,&#39;//item/itunes:duration&#39;,xmlValue)

# create data frame with important variables
Adventurezone &amp;lt;- data.frame(titles, date, duration)

# create unique identifier
Adventurezone$id &amp;lt;- &amp;quot;The Adventure Zone&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I probably could have created a function to run through all the shows, but instead I used that chunk for every show. It was actually useful as a few of the shows had missing episodes or titles and durations that didn&amp;rsquo;t match up.&lt;/p&gt;

&lt;p&gt;Once I had all the data scrapped from the feeds I was able to combine it into one dataset of 4,202 episodes from 25 different shows. The date/duration variables were pretty messy so I noodled around a bit and cleaned them up into something manageable. I&amp;rsquo;ve saved that final data in &lt;a href=&#34;https://dl.dropboxusercontent.com/u/2513399/MaximumFun.rdata&#34;&gt;Rdata&lt;/a&gt; and &lt;a href=&#34;https://dl.dropboxusercontent.com/u/2513399/MaximumFun.csv&#34;&gt;.csv&lt;/a&gt; formats if you want to play with them yourself. I&amp;rsquo;m loading the RData file here:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;load(url(&amp;quot;https://dl.dropboxusercontent.com/u/2513399/MaximumFun.rdata&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;visualizations&#34;&gt;Visualizations&lt;/h2&gt;

&lt;p&gt;Once we have all the data in a good format creating visualizations is actually pretty easy! Let&amp;rsquo;s start with a simple bar chart that plots the number of shows per month:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
# simple bar chart with sum of number of shows per month
mf.stacked.bar &amp;lt;- ggplot(MaximumFun, aes(monthyear)) + geom_bar() +
  labs(title = &amp;quot;Number of Shows on Maximum Fun per Month&amp;quot;, x = &amp;quot;Year - Month&amp;quot;, y = &amp;quot;Number of Shows Published&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
mf.stacked.bar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-3-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s not bad, but what if we wanted to know which shows were on the network over time? We can use the &amp;ldquo;id&amp;rdquo; variable we created in the initial data scrapping process to label each show. This visualization needs a better color palette to better differentiate between each show, but I&amp;rsquo;ll leave it here for now:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
# add in color to represent the shows
# needs a better color palette
mf.stacked.bar2 &amp;lt;- ggplot(MaximumFun, aes(monthyear, fill = id)) + geom_bar() +
  labs(title = &amp;quot;Number of Shows on Maximum Fun per Month&amp;quot;, x = &amp;quot;Year - Month&amp;quot;, y = &amp;quot;Number of Shows Published&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6), legend.position=&amp;quot;bottom&amp;quot;)
mf.stacked.bar2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-4-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What can we find out about each show? Let&amp;rsquo;s start with visualizing the total number of hours each podcast has published:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
mf.stacked.bar4 &amp;lt;- ggplot(MaximumFun, aes(id, (showlength/60))) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  labs(title = &amp;quot;Total Duration of Each Show on Maximum Fun&amp;quot;, x = &amp;quot;Show&amp;quot;, y = &amp;quot;Total Number of Hours&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
mf.stacked.bar4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-5-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-5&#34; /&gt;&lt;/p&gt;

&lt;p&gt;How about the number of episodes per show?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# simple bar chart for total number of episodes per show
mf.stacked.bar5 &amp;lt;- ggplot(MaximumFun, aes(id)) + geom_bar() +
  labs(title = &amp;quot;Number of Episode of each Show on Maximum Fun&amp;quot;, x = &amp;quot;Show&amp;quot;, y = &amp;quot;Total Number of Episodes&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
mf.stacked.bar5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-6-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I also got around to reformatting the data so that we could look at the number of shows and amount of content produced by Maximum Fun over time. To do that we first have to create a new dataset that aggregates some of the information:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(plyr)
# number of shows on the network over time
MaxFunShows &amp;lt;- ddply(MaximumFun, c(&amp;quot;monthyear&amp;quot;), summarise,
                           &#39;NumberofShows&#39; = length(unique(id)),
                           &#39;DurationofShows&#39; = sum(showlength, na.rm=TRUE)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we can make plots just like the ones we have above!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mf.stacked.bar5 &amp;lt;- ggplot(MaxFunShows, aes(monthyear, NumberofShows)) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  labs(title = &amp;quot;Number of Shows on Maximum Fun over time&amp;quot;, x = &amp;quot;Date&amp;quot;, y = &amp;quot;Number of Shows on the Network&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
mf.stacked.bar5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-8-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-8&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What about the amount of content over time?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mf.stacked.bar5 &amp;lt;- ggplot(MaxFunShows, aes(monthyear, (DurationofShows/60))) + geom_bar(stat=&amp;quot;identity&amp;quot;) +
  labs(title = &amp;quot;Amount of Content Produced (in hours) by Maximum Fun over time&amp;quot;, x = &amp;quot;Date&amp;quot;, y = &amp;quot;Hours&amp;quot;) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
mf.stacked.bar5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/2016-06-04-how-much-fun-is-maximum-fun/unnamed-chunk-9-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-9&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, this doesn&amp;rsquo;t include some of the great shows that have moved on to be either independtly operated or part of another network, but it&amp;rsquo;s still a pretty good approximation of the growth over time.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll probably keep noodling around with this data. Probably a lot more I can do with visualizing particular shows and the network as a whole. If you have ideas &lt;a href=&#34;http://twitter.com/eramirez&#34;&gt;get in touch&lt;/a&gt;!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing Time Series Data</title>
      <link>/post/2016/01/25/visualizing-time-series-data/</link>
      <pubDate>Mon, 25 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016/01/25/visualizing-time-series-data/</guid>
      <description>

&lt;p&gt;When working with human behavior you&amp;rsquo;ll almost always have to deal with data that is formatted as a time series. Briefly, time series data corresponds with repeated measures of a variable (or multiple variables) at consistent intervals over a period.&lt;/p&gt;

&lt;p&gt;At the Center for Wireless and Population Health Systems, we&amp;rsquo;re consistently dealing with physical activity data collected from accelerometers worn by study participants. These measurement devices sample human locomotion at various rates over periods lasting days, weeks, or even longer. There are a variety of methods to process and analyze accelerometer data, but we know any good statistician will use a variety of visualization techniques so become familiar with the data and understand it better. This document is meant to be an introduction to different methods for visualizing time series data. By no means does it cover &lt;em&gt;every&lt;/em&gt; method, but it should get you started and give you some ideas for additional techniques.&lt;/p&gt;

&lt;h2 id=&#34;the-data&#34;&gt;The Data&lt;/h2&gt;

&lt;p&gt;The data used in these examples was collected as part of my doctoral dissertation research. The physical activity data was gathered from participants who used a Fitbit activity tracker to measure their physical activity. Access to historical data was granted by participants and downloaded using &lt;a href=&#34;http://fitabase.com&#34;&gt;Fitabase&lt;/a&gt;. A variety of data was made available, but for this example we&amp;rsquo;ll be focusing on steps.&lt;/p&gt;

&lt;p&gt;As my dissertation analysis is ongoing, I&amp;rsquo;m using my own Fitbit data here for this example.&lt;/p&gt;

&lt;h2 id=&#34;step-data&#34;&gt;Step Data&lt;/h2&gt;

&lt;p&gt;I downloaded my step data over a two-year period from Jan. 1, 2012 to Jan. 1, 2014. Two data files will be used in this analysis (click to download the data sets):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://dl.dropboxusercontent.com/u/2513399/ER_FitbitDailySteps_2012.csv&#34;&gt;Daily Steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dl.dropboxusercontent.com/u/2513399/ER_FitbitMinuteSteps_2012.csv&#34;&gt;Minute-Level Steps&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The &lt;strong&gt;Daily Steps&lt;/strong&gt; file contains 366 observations of the total amount of steps recorded for each day in 2012 (2012 was a leap year). The &lt;strong&gt;Minute-Level Steps&lt;/strong&gt; file contains 527,040 observations (1,440 minutes per hour, 24 hours, 366 days) of the total steps recorded per minute for 2012.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s load &amp;lsquo;em up.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;DailySteps &amp;lt;- read.csv(&amp;quot;https://dl.dropboxusercontent.com/u/2513399/ER_FitbitDailySteps_2012.csv&amp;quot;)
MinuteSteps &amp;lt;- read.csv(&amp;quot;https://dl.dropboxusercontent.com/u/2513399/ER_FitbitMinuteSteps_2012.csv&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cleaning-the-data&#34;&gt;Cleaning the data&lt;/h2&gt;

&lt;p&gt;So the data is loaded and a quick glance indicates that the date and date/time vectors were imported as &lt;em&gt;factors&lt;/em&gt;. That&amp;rsquo;s all well and good for most things, but we&amp;rsquo;re going to want dates as dates and times as times for visualization purposes. Let&amp;rsquo;s get those corrected. I like using the &lt;a href=&#34;https://cran.r-project.org/web/packages/lubridate/index.html&#34;&gt;lubridate package&lt;/a&gt; as it handles dates and times very easily. The &lt;em&gt;ActivityDay&lt;/em&gt; vector is in mm/dd/yyyy format so we can use the &lt;em&gt;mdy&lt;/em&gt; function from lubridate to change it into a POSIXct variable.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(lubridate)
DailySteps$Date &amp;lt;- mdy(DailySteps$ActivityDay)
DailySteps$Date &amp;lt;- as.Date(DailySteps$Date)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The minute-level data is a bit trickier. The &lt;em&gt;ActivityMinute&lt;/em&gt; vector is formatted for date/time in mm/dd/yyyy hh:mm:ss AM/PM. This isn&amp;rsquo;t super useful for instance, when we want to plot the minute-by-minute steps for a full day of data. So let&amp;rsquo;s do some reformatting to clean it up.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;MinuteSteps$ActivityMinute &amp;lt;- mdy_hms(as.character(MinuteSteps$ActivityMinute))
MinuteSteps$Date &amp;lt;- as.Date(MinuteSteps$ActivityMinute, format = &amp;quot;%Y-%m-%d  %H:%M:%S&amp;quot;)
MinuteSteps$Time &amp;lt;- format(as.POSIXct(strptime(MinuteSteps$ActivityMinute, &amp;quot;%Y-%m-%d  %H:%M:%S&amp;quot;,tz=&amp;quot;&amp;quot;)) ,format = &amp;quot;%H:%M&amp;quot;)
MinuteSteps$Time &amp;lt;- as.POSIXct(MinuteSteps$Time, format = &amp;quot;%H:%M&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Why four steps to create two variables? Well, we want to make the date, a date variable, and we also want to strip the time to it&amp;rsquo;s own variable. strptime can do that, but it returns a character vector, which ggplot won&amp;rsquo;t like when use it as a scale. We have to convert that time character vector back into POSIXct and by doing so we assign it an arbitrary date. If you don&amp;rsquo;t assign it in the function then it will automatically assign today&amp;rsquo;s date.&lt;/p&gt;

&lt;p&gt;#Fist Level Visualization - Bars &amp;amp; Lines&lt;/p&gt;

&lt;h2 id=&#34;bar-plots&#34;&gt;Bar Plots&lt;/h2&gt;

&lt;p&gt;I find bar plots a bit easier to read when dealing with aggregated data such as daily step counts. This might be because I envision the volume of the bar to contain the total amount of steps for that day. So let&amp;rsquo;s make a quick bar plot of the Daily Steps.&lt;/p&gt;

&lt;p&gt;Before we begin we&amp;rsquo;ll need to load two packages: &lt;strong&gt;ggplot2&lt;/strong&gt; and &lt;strong&gt;scales&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
library(scales)
DailyStepsPlot &amp;lt;- ggplot(DailySteps, aes(x=Date, y=StepTotal)) #This will base plot which we&#39;ll manipulate.

DailyStepsPlot + geom_bar(stat=&amp;quot;identity&amp;quot;) + scale_x_date(breaks=date_breaks(&amp;quot;1 month&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-4-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;##Line Plots
What about a line plot (with added points)?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-5-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-5&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;multiple-line-plots&#34;&gt;Multiple Line Plots&lt;/h2&gt;

&lt;p&gt;Line plots aren&amp;rsquo;t that great when you have a continuous data set that spans over 500,000 observations. For a data set that large we&amp;rsquo;re typically trying to look into patterns. A good way to do that is to plot the data one level up, such as per day in this case.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll plot each day on the same canvas with each line set to a transparency of alpha = .05. I also cut down the line size so that patterns might be seen in the resulting banding.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(MinuteSteps, aes(x=Time, y=Steps, group=Date)) +
  geom_path(size=.5, alpha = 0.05, colour=&amp;quot;blue&amp;quot;) +
  scale_x_datetime(breaks=date_breaks(&amp;quot;2 hour&amp;quot;), labels=date_format(&amp;quot;%H:%M&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-6-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can see some clear banding at 120 steps/min or so and another a bit lower around 75 steps/min. It also appears that there a few days with periods of high activity (&amp;gt;150 steps/min) just past 6PM (18:00). But, could it be clearer?&lt;/p&gt;

&lt;h2 id=&#34;scatterplot&#34;&gt;Scatterplot&lt;/h2&gt;

&lt;p&gt;When using the line graph, multiple lines can obscure the patterns we&amp;rsquo;re trying to tease out by introducing a bit of visual noise. Let&amp;rsquo;s reduce the noise by taking away the lines and using just points in a scatterplot.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(MinuteSteps, aes(x=Time, y=Steps, group=Date)) +
  geom_point(size=.5, alpha = 0.1, colour=&amp;quot;blue&amp;quot;) +
  scale_x_datetime(breaks=date_breaks(&amp;quot;2 hour&amp;quot;), labels=date_format(&amp;quot;%H:%M&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-7-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-7&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;grouping-data-multiple-lines-facets-wrapping&#34;&gt;Grouping Data (Multiple Lines &amp;amp; Facets Wrapping)&lt;/h2&gt;

&lt;p&gt;So we&amp;rsquo;ve plotted every day, and we&amp;rsquo;ve plotted every minute in our data. We&amp;rsquo;ve teased out a few simple patterns, but what about other distinctions in the data?&lt;/p&gt;

&lt;p&gt;One of the methods common in physical activity data analysis is to explore differences across different days of the week. Are individuals more active on certain days of the week? How about the difference between weekdays and weekend days?&lt;/p&gt;

&lt;p&gt;To be able to create visualizations that help us understand these potential differences we&amp;rsquo;ll have to do a bit of work on the data.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s create a &lt;em&gt;Day&lt;/em&gt; variable for our Daily data set. Again, we&amp;rsquo;re turning to the &lt;strong&gt;lubridate&lt;/strong&gt; package. Lubridate has function called &lt;strong&gt;&lt;em&gt;wday&lt;/em&gt;&lt;/strong&gt; which will return the day of the week.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;DailySteps$Day &amp;lt;- wday(DailySteps$Date, label = TRUE) # we use labels=true here to return day labels instead of numeric values.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s see if we can plot differences between days:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(DailySteps, aes(x=Date, y=StepTotal, group=Day, colour=Day)) + geom_path() + geom_point() + scale_x_date(breaks=date_breaks(&amp;quot;1 month&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-9-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-9&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Well, that&amp;rsquo;s a mess. What if we graph each day individually? We can do this by calling creating multiple facets of the same plot.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(DailySteps, aes(x=Date, y=StepTotal, colour=Day)) +
  geom_path() +
  geom_point() +
  scale_x_date(breaks=date_breaks(&amp;quot;1 month&amp;quot;)) +
  facet_grid(Day ~.) +
  theme(legend.position=&amp;quot;none&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-10-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-10&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s a bit better, but I personally think the week starts on Monday, not Sunday. Let&amp;rsquo;s fix that in our data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;DailySteps$Day2 &amp;lt;- factor(DailySteps$Day, levels = c(&amp;quot;Mon&amp;quot;, &amp;quot;Tues&amp;quot;, &amp;quot;Wed&amp;quot;, &amp;quot;Thurs&amp;quot;, &amp;quot;Fri&amp;quot;, &amp;quot;Sat&amp;quot;, &amp;quot;Sun&amp;quot;))

ggplot(DailySteps, aes(x=Date, y=StepTotal, colour=Day2)) +
  geom_path() +
  geom_point() +
  scale_x_date(breaks=date_breaks(&amp;quot;1 month&amp;quot;)) +
  facet_grid(Day2 ~.) +
  theme(legend.position=&amp;quot;none&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-11-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-11&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Okay, that was fun. But let&amp;rsquo;s get to the minute data. We&amp;rsquo;re basically going to do the same type of processing on the minute level data to get day of the week and then we&amp;rsquo;ll create a few different plots.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;MinuteSteps$Day &amp;lt;- wday(MinuteSteps$Date, label = TRUE)
MinuteSteps$Day2 &amp;lt;- factor(DailySteps$Day, levels = c(&amp;quot;Mon&amp;quot;, &amp;quot;Tues&amp;quot;, &amp;quot;Wed&amp;quot;, &amp;quot;Thurs&amp;quot;, &amp;quot;Fri&amp;quot;, &amp;quot;Sat&amp;quot;, &amp;quot;Sun&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you might be able to guess, plotting all the minute-level data points, even when coloured by group, is a complete mess. We&amp;rsquo;ll start with a facetted plot.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(MinuteSteps, aes(x=Time, y=Steps, colour=Day2)) +
  geom_point(size=.5, alpha = 0.1) +
  scale_x_datetime(breaks=date_breaks(&amp;quot;2 hour&amp;quot;), labels=date_format(&amp;quot;%H:%M&amp;quot;)) +
  facet_grid(Day2 ~.) +
  theme(legend.position=&amp;quot;none&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-13-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-13&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Well, that&amp;rsquo;s nice to look at, but still hard to understand any type of trends or patterns. Since we have so much data, we can probably better understand what&amp;rsquo;s going on by collapsing it. For instance, we might want to know what an &amp;ldquo;average Monday&amp;rdquo; might look like. That&amp;rsquo;s easy to do!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;MinuteSteps.AvgDays &amp;lt;- aggregate(Steps ~ Time + Day2, MinuteSteps, mean)

ggplot(MinuteSteps.AvgDays, aes(x=Time, y=Steps, colour=Day2)) +
  geom_path() +
  scale_x_datetime(breaks=date_breaks(&amp;quot;2 hour&amp;quot;), labels=date_format(&amp;quot;%H:%M&amp;quot;)) +
  facet_grid(Day2 ~.) +
  theme(legend.position=&amp;quot;none&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/figure/source/VisualizingTimeSeriesData/unnamed-chunk-14-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-14&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>